
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="yJin's Blog">
      
      
        <meta name="author" content="Aleksa Gordic">
      
      
      
        <link rel="prev" href="../fzu_cs_course/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/FZU-SINTEF-Beamer-Template.html">
      
      
        <link rel="next" href="../csdiy/CMU%2010-414%20Deep%20Learning%20Systems/index.html">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>vLLM深入研究：一个高吞吐量 LLM 推理系统的剖析 - JinBlog</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      
  
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  
  
  <style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M1%207.775V2.75C1%201.784%201.784%201%202.75%201h5.025c.464%200%20.91.184%201.238.513l6.25%206.25a1.75%201.75%200%200%201%200%202.474l-5.026%205.026a1.75%201.75%200%200%201-2.474%200l-6.25-6.25A1.75%201.75%200%200%201%201%207.775m1.5%200c0%20.066.026.13.073.177l6.25%206.25a.25.25%200%200%200%20.354%200l5.025-5.025a.25.25%200%200%200%200-.354l-6.25-6.25a.25.25%200%200%200-.177-.073H2.75a.25.25%200%200%200-.25.25ZM6%205a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E');--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2.5%201.75v11.5c0%20.138.112.25.25.25h3.17a.75.75%200%200%201%200%201.5H2.75A1.75%201.75%200%200%201%201%2013.25V1.75C1%20.784%201.784%200%202.75%200h8.5C12.216%200%2013%20.784%2013%201.75v7.736a.75.75%200%200%201-1.5%200V1.75a.25.25%200%200%200-.25-.25h-8.5a.25.25%200%200%200-.25.25m13.274%209.537zl-4.557%204.45a.75.75%200%200%201-1.055-.008l-1.943-1.95a.75.75%200%200%201%201.062-1.058l1.419%201.425%204.026-3.932a.75.75%200%201%201%201.048%201.074M4.75%204h4.5a.75.75%200%200%201%200%201.5h-4.5a.75.75%200%200%201%200-1.5M4%207.75A.75.75%200%200%201%204.75%207h2a.75.75%200%200%201%200%201.5h-2A.75.75%200%200%201%204%207.75%22/%3E%3C/svg%3E');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M0%208a8%208%200%201%201%2016%200A8%208%200%200%201%200%208m8-6.5a6.5%206.5%200%201%200%200%2013%206.5%206.5%200%200%200%200-13M6.5%207.75A.75.75%200%200%201%207.25%207h1a.75.75%200%200%201%20.75.75v2.75h.25a.75.75%200%200%201%200%201.5h-2a.75.75%200%200%201%200-1.5h.25v-2h-.25a.75.75%200%200%201-.75-.75M8%206a1%201%200%201%201%200-2%201%201%200%200%201%200%202%22/%3E%3C/svg%3E');--md-admonition-icon--tip:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M3.499.75a.75.75%200%200%201%201.5%200v.996C5.9%202.903%206.793%203.65%207.662%204.376l.24.202c-.036-.694.055-1.422.426-2.163C9.1.873%2010.794-.045%2012.622.26%2014.408.558%2016%201.94%2016%204.25c0%201.278-.954%202.575-2.44%202.734l.146.508.065.22c.203.701.412%201.455.476%202.226.142%201.707-.4%203.03-1.487%203.898C11.714%2014.671%2010.27%2015%208.75%2015h-6a.75.75%200%200%201%200-1.5h1.376a4.5%204.5%200%200%201-.563-1.191%203.84%203.84%200%200%201-.05-2.063%204.65%204.65%200%200%201-2.025-.293.75.75%200%200%201%20.525-1.406c1.357.507%202.376-.006%202.698-.318l.009-.01a.747.747%200%200%201%201.06%200%20.75.75%200%200%201-.012%201.074c-.912.92-.992%201.835-.768%202.586.221.74.745%201.337%201.196%201.621H8.75c1.343%200%202.398-.296%203.074-.836.635-.507%201.036-1.31.928-2.602-.05-.603-.216-1.224-.422-1.93l-.064-.221c-.12-.407-.246-.84-.353-1.29a2.4%202.4%200%200%201-.507-.441%203.1%203.1%200%200%201-.633-1.248.75.75%200%200%201%201.455-.364c.046.185.144.436.31.627.146.168.353.305.712.305.738%200%201.25-.615%201.25-1.25%200-1.47-.95-2.315-2.123-2.51-1.172-.196-2.227.387-2.706%201.345-.46.92-.27%201.774.019%203.062l.042.19.01.05c.348.443.666.949.94%201.553a.75.75%200%201%201-1.365.62c-.553-1.217-1.32-1.94-2.3-2.768L6.7%205.527c-.814-.68-1.75-1.462-2.692-2.619a3.7%203.7%200%200%200-1.023.88c-.406.495-.663%201.036-.722%201.508.116.122.306.21.591.239.388.038.797-.06%201.032-.19a.75.75%200%200%201%20.728%201.31c-.515.287-1.23.439-1.906.373-.682-.067-1.473-.38-1.879-1.193L.75%205.677V5.5c0-.984.48-1.94%201.077-2.664.46-.559%201.05-1.055%201.673-1.353z%22/%3E%3C/svg%3E');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M13.78%204.22a.75.75%200%200%201%200%201.06l-7.25%207.25a.75.75%200%200%201-1.06%200L2.22%209.28a.75.75%200%200%201%20.018-1.042.75.75%200%200%201%201.042-.018L6%2010.94l6.72-6.72a.75.75%200%200%201%201.06%200%22/%3E%3C/svg%3E');--md-admonition-icon--question:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M0%208a8%208%200%201%201%2016%200A8%208%200%200%201%200%208m8-6.5a6.5%206.5%200%201%200%200%2013%206.5%206.5%200%200%200%200-13M6.92%206.085h.001a.749.749%200%201%201-1.342-.67c.169-.339.436-.701.849-.977C6.845%204.16%207.369%204%208%204a2.76%202.76%200%200%201%201.637.525c.503.377.863.965.863%201.725%200%20.448-.115.83-.329%201.15-.205.307-.47.513-.692.662-.109.072-.22.138-.313.195l-.006.004a6%206%200%200%200-.26.16%201%201%200%200%200-.276.245.75.75%200%200%201-1.248-.832c.184-.264.42-.489.692-.661q.154-.1.313-.195l.007-.004c.1-.061.182-.11.258-.161a1%201%200%200%200%20.277-.245C8.96%206.514%209%206.427%209%206.25a.61.61%200%200%200-.262-.525A1.27%201.27%200%200%200%208%205.5c-.369%200-.595.09-.74.187a1%201%200%200%200-.34.398M9%2011a1%201%200%201%201-2%200%201%201%200%200%201%202%200%22/%3E%3C/svg%3E');--md-admonition-icon--warning:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M6.457%201.047c.659-1.234%202.427-1.234%203.086%200l6.082%2011.378A1.75%201.75%200%200%201%2014.082%2015H1.918a1.75%201.75%200%200%201-1.543-2.575Zm1.763.707a.25.25%200%200%200-.44%200L1.698%2013.132a.25.25%200%200%200%20.22.368h12.164a.25.25%200%200%200%20.22-.368Zm.53%203.996v2.5a.75.75%200%200%201-1.5%200v-2.5a.75.75%200%200%201%201.5%200M9%2011a1%201%200%201%201-2%200%201%201%200%200%201%202%200%22/%3E%3C/svg%3E');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2.344%202.343za8%208%200%200%201%2011.314%2011.314A8.002%208.002%200%200%201%20.234%2010.089a8%208%200%200%201%202.11-7.746m1.06%2010.253a6.5%206.5%200%201%200%209.108-9.275%206.5%206.5%200%200%200-9.108%209.275M6.03%204.97%208%206.94l1.97-1.97a.749.749%200%200%201%201.275.326.75.75%200%200%201-.215.734L9.06%208l1.97%201.97a.749.749%200%200%201-.326%201.275.75.75%200%200%201-.734-.215L8%209.06l-1.97%201.97a.749.749%200%200%201-1.275-.326.75.75%200%200%201%20.215-.734L6.94%208%204.97%206.03a.75.75%200%200%201%20.018-1.042.75.75%200%200%201%201.042-.018%22/%3E%3C/svg%3E');--md-admonition-icon--danger:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M9.504.43a1.516%201.516%200%200%201%202.437%201.713L10.415%205.5h2.123c1.57%200%202.346%201.909%201.22%203.004l-7.34%207.142a1.25%201.25%200%200%201-.871.354h-.302a1.25%201.25%200%200%201-1.157-1.723L5.633%2010.5H3.462c-1.57%200-2.346-1.909-1.22-3.004zm1.047%201.074L3.286%208.571A.25.25%200%200%200%203.462%209H6.75a.75.75%200%200%201%20.694%201.034l-1.713%204.188%206.982-6.793A.25.25%200%200%200%2012.538%207H9.25a.75.75%200%200%201-.683-1.06l2.008-4.418.003-.006-.004-.009-.006-.006-.008-.001q-.005%200-.009.004%22/%3E%3C/svg%3E');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M4.72.22a.75.75%200%200%201%201.06%200l1%20.999a3.5%203.5%200%200%201%202.441%200l.999-1a.748.748%200%200%201%201.265.332.75.75%200%200%201-.205.729l-.775.776c.616.63.995%201.493.995%202.444v.327q0%20.15-.025.292c.408.14.764.392%201.029.722l1.968-.787a.75.75%200%200%201%20.556%201.392L13%207.258V9h2.25a.75.75%200%200%201%200%201.5H13v.5q-.002.615-.141%201.186l2.17.868a.75.75%200%200%201-.557%201.392l-2.184-.873A5%205%200%200%201%208%2016a5%205%200%200%201-4.288-2.427l-2.183.873a.75.75%200%200%201-.558-1.392l2.17-.868A5%205%200%200%201%203%2011v-.5H.75a.75.75%200%200%201%200-1.5H3V7.258L.971%206.446a.75.75%200%200%201%20.558-1.392l1.967.787c.265-.33.62-.583%201.03-.722a1.7%201.7%200%200%201-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72%201.28a.75.75%200%200%201%200-1.06m.53%206.28a.75.75%200%200%200-.75.75V11a3.5%203.5%200%201%200%207%200V7.25a.75.75%200%200%200-.75-.75ZM6.173%205h3.654A.17.17%200%200%200%2010%204.827V4.5a2%202%200%201%200-4%200v.327c0%20.096.077.173.173.173%22/%3E%3C/svg%3E');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5%205.782V2.5h-.25a.75.75%200%200%201%200-1.5h6.5a.75.75%200%200%201%200%201.5H11v3.282l3.666%205.76C15.619%2013.04%2014.543%2015%2012.767%2015H3.233c-1.776%200-2.852-1.96-1.899-3.458Zm-2.4%206.565a.75.75%200%200%200%20.633%201.153h9.534a.75.75%200%200%200%20.633-1.153L12.225%2010.5h-8.45ZM9.5%202.5h-3V6c0%20.143-.04.283-.117.403L4.73%209h6.54L9.617%206.403A.75.75%200%200%201%209.5%206Z%22/%3E%3C/svg%3E');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M1.75%202.5h10.5a.75.75%200%200%201%200%201.5H1.75a.75.75%200%200%201%200-1.5m4%205h8.5a.75.75%200%200%201%200%201.5h-8.5a.75.75%200%200%201%200-1.5m0%205h8.5a.75.75%200%200%201%200%201.5h-8.5a.75.75%200%200%201%200-1.5M2.5%207.75v6a.75.75%200%200%201-1.5%200v-6a.75.75%200%200%201%201.5%200%22/%3E%3C/svg%3E');}</style>



    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#vllm-llm" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../index.html" title="JinBlog" class="md-header__button md-logo" aria-label="JinBlog" data-md-component="logo">
      
  <img src="../assests/jade_light.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            JinBlog
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              vLLM深入研究：一个高吞吐量 LLM 推理系统的剖析
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="orange"  aria-label="暗色模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="暗色模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="亮色模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="亮色模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/yJader/JinBlog" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    yJader/JinBlog
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../index.html" class="md-tabs__link">
        
  
  
    
  
  Jin Blog

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../fzu_cs_course/index.html" class="md-tabs__link">
          
  
  
    
  
  FZU CS课程

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="Inside%20vLLM%20Anatomy%20of%20a%20High-Throughput%20LLM%20Inference%20System.html" class="md-tabs__link">
          
  
  
    
  
  DL-LLM

        </a>
      </li>
    
  

    
  

      
        
  
  
  
  
    
    
      
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../csdiy/CMU%2010-414%20Deep%20Learning%20Systems/index.html" class="md-tabs__link">
          
  
  
    
  
  CSDIY公开课

        </a>
      </li>
    
  

    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../tools/Windows%E8%A3%85%E6%9C%BA%E7%AC%94%E8%AE%B0%28%E9%99%84%E8%BD%AF%E4%BB%B6%E6%8E%A8%E8%8D%90%29.html" class="md-tabs__link">
          
  
  
    
  
  工具分享

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../blog/index.html" class="md-tabs__link">
          
  
  
    
  
  Blog

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../index.html" title="JinBlog" class="md-nav__button md-logo" aria-label="JinBlog" data-md-component="logo">
      
  <img src="../assests/jade_light.svg" alt="logo">

    </a>
    JinBlog
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/yJader/JinBlog" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    yJader/JinBlog
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Jin Blog
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../fzu_cs_course/index.html" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    FZU CS课程
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            FZU CS课程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    数字电路与逻辑设计
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            数字电路与逻辑设计
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF%E4%B8%8E%E9%80%BB%E8%BE%91%E8%AE%BE%E8%AE%A1/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF%E4%B8%8E%E9%80%BB%E8%BE%91%E8%AE%BE%E8%AE%A1.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    数字电路与逻辑设计
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF%E4%B8%8E%E9%80%BB%E8%BE%91%E8%AE%BE%E8%AE%A1/%E5%A4%8D%E4%B9%A0%E7%BA%B2%E8%A6%81.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    复习纲要
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    离散数学
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4" >
        
          
          <label class="md-nav__link" for="__nav_2_4" id="__nav_2_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    数据结构
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            数据结构
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    数据结构
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E8%80%83%E8%AF%95%E6%9D%90%E6%96%99.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    数据结构考试材料
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_5" >
        
          
          <label class="md-nav__link" for="__nav_2_5" id="__nav_2_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    计算机组成原理
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_5">
            <span class="md-nav__icon md-icon"></span>
            计算机组成原理
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    计算机组成原理
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E8%80%83%E7%82%B9.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    计算机组成原理考点
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_6" >
        
          
          <label class="md-nav__link" for="__nav_2_6" id="__nav_2_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    计算机网络
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_6">
            <span class="md-nav__icon md-icon"></span>
            计算机网络
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    计算机网络
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%20%E8%AF%BE%E5%90%8E%E9%A2%98.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    课后题
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_7" >
        
          
          <label class="md-nav__link" for="__nav_2_7" id="__nav_2_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    操作系统
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_7">
            <span class="md-nav__icon md-icon"></span>
            操作系统
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    操作系统
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/NJU%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    NJU操作系统
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%AE%80%E7%AD%94%E9%A2%98%20MDver.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    简答题
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_8" >
        
          
          <label class="md-nav__link" for="__nav_2_8" id="__nav_2_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    软件工程
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_8">
            <span class="md-nav__icon md-icon"></span>
            软件工程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    软件工程
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E4%B8%80%E4%BA%9B%E6%95%B4%E7%90%86.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    知识点
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_9" >
        
          
          <label class="md-nav__link" for="__nav_2_9" id="__nav_2_9_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    数据库系统原理
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_9">
            <span class="md-nav__icon md-icon"></span>
            数据库系统原理
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    数据库系统原理
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%80%E7%AD%94%E9%A2%98.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    简答题
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E5%9B%BE%E5%BD%A2%E5%AD%A6/%E5%9B%BE%E5%BD%A2%E5%AD%A6.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    计算机图形学
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_11" >
        
          
          <label class="md-nav__link" for="__nav_2_11" id="__nav_2_11_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    汇编&接口
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_11">
            <span class="md-nav__icon md-icon"></span>
            汇编&接口
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E6%B1%87%E7%BC%96%26%E6%8E%A5%E5%8F%A3/%E6%B1%87%E7%BC%96%26%E6%8E%A5%E5%8F%A3.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    汇编&接口
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E6%B1%87%E7%BC%96%26%E6%8E%A5%E5%8F%A3/%E6%B1%87%E7%BC%96%E6%A8%A1%E6%9D%BF.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    汇编模板
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_12" >
        
          
          <label class="md-nav__link" for="__nav_2_12" id="__nav_2_12_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    劳动实践(BearPi)
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_12">
            <span class="md-nav__icon md-icon"></span>
            劳动实践(BearPi)
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E5%8A%B3%E5%8A%A8%E5%AE%9E%E8%B7%B5%28BearPi%29/%E5%8A%B3%E5%8A%A8%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    劳动实践(BearPi)笔记
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_13" >
        
          
          <label class="md-nav__link" for="__nav_2_13" id="__nav_2_13_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    数据挖掘
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_13">
            <span class="md-nav__icon md-icon"></span>
            数据挖掘
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    数据挖掘
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_14" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../fzu_cs_course/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84/index.html" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    计算机系统结构
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_14" id="__nav_2_14_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_14">
            <span class="md-nav__icon md-icon"></span>
            计算机系统结构
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84/%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    系统结构
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84/%E5%A4%8D%E4%B9%A0%E6%8F%90%E7%BA%B2MAP.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    复习提纲MAP
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84/%E7%AE%80%E7%AD%94%E9%A2%98.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    简答题
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84/%E5%B0%8F%E6%B5%8B%E9%80%89%E5%A1%AB.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    小测选填
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_15" >
        
          
          <label class="md-nav__link" for="__nav_2_15" id="__nav_2_15_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    编译原理
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_15_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_15">
            <span class="md-nav__icon md-icon"></span>
            编译原理
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    编译原理
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_16" >
        
          
          <label class="md-nav__link" for="__nav_2_16" id="__nav_2_16_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    计算方法(数值分析)
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_16_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_16">
            <span class="md-nav__icon md-icon"></span>
            计算方法(数值分析)
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%28%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%29/%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%28%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%29.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    计算方法(数值分析)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%28%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%29/%E5%85%AC%E5%BC%8F%E6%95%B4%E7%90%86.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    公式整理
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_17" >
        
          
          <label class="md-nav__link" for="__nav_2_17" id="__nav_2_17_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    人机交互
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_17_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_17">
            <span class="md-nav__icon md-icon"></span>
            人机交互
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E4%BA%BA%E6%9C%BA%E4%BA%A4%E4%BA%92/%E5%A4%8D%E4%B9%A0%E8%AF%BE%E4%BB%B6%20MD%20Ver.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    人机交互
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E4%BA%BA%E6%9C%BA%E4%BA%A4%E4%BA%92/%E7%BC%A9%E5%87%8F%E7%89%88.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    人机交互考点
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_18" >
        
          
          <label class="md-nav__link" for="__nav_2_18" id="__nav_2_18_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    毕业设计
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_18_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_18">
            <span class="md-nav__icon md-icon"></span>
            毕业设计
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/%E6%AF%95%E8%AE%BE%E8%A6%81%E6%B1%82%E6%95%B4%E7%90%86.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    毕业设计要求整理
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/FZU-Undergraduate-Thesis.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FZU-Undergraduate-Thesis
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fzu_cs_course/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/FZU-SINTEF-Beamer-Template.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FZU-SINTEF-Beamer-Template
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    DL-LLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            DL-LLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" checked>
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    博客学习
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            博客学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    vLLM深入研究：一个高吞吐量 LLM 推理系统的剖析
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="Inside%20vLLM%20Anatomy%20of%20a%20High-Throughput%20LLM%20Inference%20System.html" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    vLLM深入研究：一个高吞吐量 LLM 推理系统的剖析
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#vllm-llm" class="md-nav__link">
    <span class="md-ellipsis">
      vLLM 深入研究：一个高吞吐量 LLM 推理系统的剖析
    </span>
  </a>
  
    <nav class="md-nav" aria-label="vLLM 深入研究：一个高吞吐量 LLM 推理系统的剖析">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#paged-attentioncontinuous-batchingprefix-cachingspeculative-decoding-gpu" class="md-nav__link">
    <span class="md-ellipsis">
      从 Paged Attention、Continuous Batching、Prefix Caching、Speculative Decoding 等到多 GPU、多节点大规模动态服务
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-engine-engine-core" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Engine &amp; Engine Core
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LLM Engine &amp; Engine Core">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#llm" class="md-nav__link">
    <span class="md-ellipsis">
      LLM 引擎构造函数
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generate" class="md-nav__link">
    <span class="md-ellipsis">
      generate 函数
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      调度器
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      运行前向传播
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      高级功能 — 扩展核心引擎逻辑
    </span>
  </a>
  
    <nav class="md-nav" aria-label="高级功能 — 扩展核心引擎逻辑">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#chunked-prefill" class="md-nav__link">
    <span class="md-ellipsis">
      Chunked Prefill
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prefix-caching" class="md-nav__link">
    <span class="md-ellipsis">
      Prefix Caching
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#guided-decoding-fsm" class="md-nav__link">
    <span class="md-ellipsis">
      Guided Decoding (FSM)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#speculative-decoding" class="md-nav__link">
    <span class="md-ellipsis">
      Speculative Decoding
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#disaggregated-pd" class="md-nav__link">
    <span class="md-ellipsis">
      Disaggregated P/D
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#uniprocexecutor-multiprocexecutor" class="md-nav__link">
    <span class="md-ellipsis">
      从 UniprocExecutor 到 MultiProcExecutor
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vllm" class="md-nav__link">
    <span class="md-ellipsis">
      分布式系统服务 vLLM
    </span>
  </a>
  
    <nav class="md-nav" aria-label="分布式系统服务 vLLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      在无头服务器节点上
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#api" class="md-nav__link">
    <span class="md-ellipsis">
      在 API 服务器节点上
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#-vs" class="md-nav__link">
    <span class="md-ellipsis">
      基准测试和自动调优-延迟vs吞吐量
    </span>
  </a>
  
    <nav class="md-nav" aria-label="基准测试和自动调优-延迟vs吞吐量">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vllm_1" class="md-nav__link">
    <span class="md-ellipsis">
      如何在 vLLM 中进行基准测试
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      结语
    </span>
  </a>
  
    <nav class="md-nav" aria-label="结语">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      致谢
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      参考文献
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../csdiy/CMU%2010-414%20Deep%20Learning%20Systems/index.html" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    CMU10-414/714: Deep Learning Systems
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            CMU10-414/714: Deep Learning Systems
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../csdiy/CMU%2010-414%20Deep%20Learning%20Systems/10-414_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Course Notes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../csdiy/CMU%2010-414%20Deep%20Learning%20Systems/10-414%20Homework%E7%AC%94%E8%AE%B0.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Homework Notes
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    CSDIY公开课
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            CSDIY公开课
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../csdiy/CMU%2010-414%20Deep%20Learning%20Systems/index.html" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    CMU10-414/714: Deep Learning Systems
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            CMU10-414/714: Deep Learning Systems
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../csdiy/CMU%2010-414%20Deep%20Learning%20Systems/10-414_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Course Notes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../csdiy/CMU%2010-414%20Deep%20Learning%20Systems/10-414%20Homework%E7%AC%94%E8%AE%B0.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Homework Notes
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../csdiy/CS224w%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.html" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    CS224W图机器学习
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            CS224W图机器学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../csdiy/CS224w%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/CS224w.pdf" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    CS224w Notes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../csdiy/CS224w%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/CS224W%20%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    CS224w 图机器学习笔记
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    工具分享
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            工具分享
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tools/Windows%E8%A3%85%E6%9C%BA%E7%AC%94%E8%AE%B0%28%E9%99%84%E8%BD%AF%E4%BB%B6%E6%8E%A8%E8%8D%90%29.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Windows装机笔记(附软件推荐)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tools/Linux%E8%A3%85%E6%9C%BA%E7%AC%94%E8%AE%B0.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Linux装机笔记
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../blog/index.html" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Blog
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6" id="__nav_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Blog
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2" >
        
          
          <label class="md-nav__link" for="__nav_6_2" id="__nav_6_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    归档
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2">
            <span class="md-nav__icon md-icon"></span>
            归档
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../blog/archive/2024.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2024
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3" >
        
          
          <label class="md-nav__link" for="__nav_6_3" id="__nav_6_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    分类
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3">
            <span class="md-nav__icon md-icon"></span>
            分类
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../blog/category/%E6%9D%82%E9%A1%B9.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    杂项
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../blog/category/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    踩坑记录
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#vllm-llm" class="md-nav__link">
    <span class="md-ellipsis">
      vLLM 深入研究：一个高吞吐量 LLM 推理系统的剖析
    </span>
  </a>
  
    <nav class="md-nav" aria-label="vLLM 深入研究：一个高吞吐量 LLM 推理系统的剖析">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#paged-attentioncontinuous-batchingprefix-cachingspeculative-decoding-gpu" class="md-nav__link">
    <span class="md-ellipsis">
      从 Paged Attention、Continuous Batching、Prefix Caching、Speculative Decoding 等到多 GPU、多节点大规模动态服务
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-engine-engine-core" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Engine &amp; Engine Core
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LLM Engine &amp; Engine Core">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#llm" class="md-nav__link">
    <span class="md-ellipsis">
      LLM 引擎构造函数
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generate" class="md-nav__link">
    <span class="md-ellipsis">
      generate 函数
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      调度器
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      运行前向传播
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      高级功能 — 扩展核心引擎逻辑
    </span>
  </a>
  
    <nav class="md-nav" aria-label="高级功能 — 扩展核心引擎逻辑">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#chunked-prefill" class="md-nav__link">
    <span class="md-ellipsis">
      Chunked Prefill
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prefix-caching" class="md-nav__link">
    <span class="md-ellipsis">
      Prefix Caching
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#guided-decoding-fsm" class="md-nav__link">
    <span class="md-ellipsis">
      Guided Decoding (FSM)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#speculative-decoding" class="md-nav__link">
    <span class="md-ellipsis">
      Speculative Decoding
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#disaggregated-pd" class="md-nav__link">
    <span class="md-ellipsis">
      Disaggregated P/D
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#uniprocexecutor-multiprocexecutor" class="md-nav__link">
    <span class="md-ellipsis">
      从 UniprocExecutor 到 MultiProcExecutor
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vllm" class="md-nav__link">
    <span class="md-ellipsis">
      分布式系统服务 vLLM
    </span>
  </a>
  
    <nav class="md-nav" aria-label="分布式系统服务 vLLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      在无头服务器节点上
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#api" class="md-nav__link">
    <span class="md-ellipsis">
      在 API 服务器节点上
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#-vs" class="md-nav__link">
    <span class="md-ellipsis">
      基准测试和自动调优-延迟vs吞吐量
    </span>
  </a>
  
    <nav class="md-nav" aria-label="基准测试和自动调优-延迟vs吞吐量">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vllm_1" class="md-nav__link">
    <span class="md-ellipsis">
      如何在 vLLM 中进行基准测试
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      结语
    </span>
  </a>
  
    <nav class="md-nav" aria-label="结语">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      致谢
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      参考文献
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/yJader/JinBlog/edit/main/docs/dl_llm/Inside vLLM Anatomy of a High-Throughput LLM Inference System.md" title="编辑此页" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  


  <h1>vLLM深入研究：一个高吞吐量 LLM 推理系统的剖析</h1>

<h2 id="vllm-llm">vLLM 深入研究：一个高吞吐量 LLM 推理系统的剖析<a class="headerlink" href="#vllm-llm" title="Permanent link">&para;</a></h2>
<blockquote>
<p>[!NOTE]
最初发布于 <a href="https://www.aleksagordic.com/blog/vllm" title="null">Aleksa Gordic 的网站</a></p>
<p>引用自<a href="https://blog.vllm.ai/2025/09/05/anatomy-of-vllm.html">Inside vLLM: Anatomy of a High-Throughput LLM Inference System | vLLM Blog</a>
我在AI的协助下进行了全文翻译</p>
</blockquote>
<h4 id="paged-attentioncontinuous-batchingprefix-cachingspeculative-decoding-gpu">从 Paged Attention、Continuous Batching、Prefix Caching、Speculative Decoding 等到多 GPU、多节点大规模动态服务<a class="headerlink" href="#paged-attentioncontinuous-batchingprefix-cachingspeculative-decoding-gpu" title="Permanent link">&para;</a></h4>
<p>在这篇文章中，我将逐步介绍构成现代高吞吐量 LLM 推理系统的所有核心系统组件和高级功能。我将特别详细分析 vLLM [1] 的工作原理。</p>
<p>这篇文章是一个系列的第一篇。它从宏观入手，然后层层深入细节（遵循倒金字塔方法），这样你可以在不陷入细枝末节的情况下，形成一个对整个系统准确的高层次心智模型。</p>
<p>后续的文章将深入探讨特定的子系统。</p>
<p>本文分为五个部分：</p>
<ol>
<li><strong>LLM Engine &amp; Engine Core</strong>：vLLM 的基础知识（调度、Paged Attention、Continuous Batching 等）</li>
<li><strong>高级功能</strong>：扩展核心引擎逻辑（Chunked Prefill、Prefix Caching、Guided &amp; Speculative Decoding、Disaggregated P/D）</li>
<li><strong>扩展</strong>：从单 GPU 到多 GPU 执行</li>
<li><strong>服务层</strong>：分布式/并发 Web 服务架构</li>
<li><strong>基准测试和自动调优</strong>：衡量延迟和吞吐量</li>
</ol>
<blockquote>
<p>[!NOTE]</p>
<ul>
<li>分析基于 <a href="https://github.com/vllm-project/vllm/tree/42172ad" title="null">commit 42172ad</a>（2025 年 8 月 9 日）。</li>
<li>目标读者：对最先进的 LLM 引擎工作原理感到好奇的任何人，以及有兴趣为 vLLM、SGLang 等做出贡献的人。</li>
<li>我将重点关注 <a href="https://docs.vllm.ai/en/latest/usage/v1_guide.html" title="null">V1 引擎</a>。我也研究了 V0（现已<a href="https://github.com/vllm-project/vllm/issues/18571" title="null">弃用</a>），这对于理解项目的演变很有价值，许多概念仍然适用。</li>
<li>关于 LLM Engine / Engine Core 的第一部分可能有点让人不知所措/枯燥——但博客的其余部分有大量的例子和图示。:)</li>
</ul>
</blockquote>
<h3 id="llm-engine-engine-core">LLM Engine &amp; Engine Core<a class="headerlink" href="#llm-engine-engine-core" title="Permanent link">&para;</a></h3>
<p>LLM 引擎是 vLLM 的基本构建块。它本身就已经可以实现高吞吐量推理——但仅限于离线设置。你还不能通过网络向客户提供服务。</p>
<p>我们将使用以下离线推理代码片段作为我们的运行示例（改编自 <a href="https://github.com/vllm-project/vllm/blob/main/examples/offline_inference/basic/basic.py" title="null">basic.py</a>）。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">vllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLM</span><span class="p">,</span> <span class="n">SamplingParams</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="s2">&quot;Hello, my name is&quot;</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="s2">&quot;The president of the United States is&quot;</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">]</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="n">sampling_params</span> <span class="o">=</span> <span class="n">SamplingParams</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">():</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="n">llm</span> <span class="o">=</span> <span class="n">LLM</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;TinyLlama/TinyLlama-1.1B-Chat-v1.0&quot;</span><span class="p">)</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="n">main</span><span class="p">()</span>
</span></code></pre></div>
<blockquote>
<p>[!NOTE]
环境变量：</p>
<ul>
<li>VLLM_USE_V1=”1” # 我们使用的是 V1 引擎</li>
<li>VLLM_ENABLE_V1_MULTIPROCESSING=”0” # 我们在单个进程中运行</li>
</ul>
</blockquote>
<p>此配置为：</p>
<ul>
<li>离线（没有 Web/分布式系统架构）</li>
<li>同步（所有执行都在单个阻塞进程中进行）</li>
<li>单 GPU（没有数据/模型/流水线/专家并行；DP/TP/PP/EP = 1）</li>
<li>使用标准 Transformer [2]（支持像 Jamba 这样的混合模型需要更复杂的混合 KV-cache 内存分配器）</li>
</ul>
<p>从这里开始，我们将逐步构建一个在线、异步、多 GPU、多节点的推理系统——但仍然服务于一个标准的 Transformer。</p>
<p>在这个例子中，我们做了两件事：</p>
<ol>
<li>实例化一个引擎</li>
<li>调用它的 <code>generate</code> 方法，根据给定的prompts进行采样</li>
</ol>
<p>让我们从分析构造函数开始。</p>
<h4 id="llm">LLM 引擎构造函数<a class="headerlink" href="#llm" title="Permanent link">&para;</a></h4>
<p>引擎的主要组件是：</p>
<ul>
<li><strong>vLLM 配置</strong>（包含配置模型、缓存、并行性等的所有选项）</li>
<li><strong>处理器</strong>（通过验证、分词和处理将原始输入转换为 <code>EngineCoreRequests</code>）</li>
<li><strong>Engine Core 客户端</strong>（在我们的运行示例中，我们使用的是 <code>InprocClient</code>，它基本上等同于 <code>EngineCore</code>；我们将逐步升级到 <code>DPLBAsyncMPClient</code>，它允许大规模服务）</li>
<li><strong>输出处理器</strong>（将原始的 <code>EngineCoreOutputs</code> 转换为用户看到的 <code>RequestOutput</code>）</li>
</ul>
<blockquote>
<p>[!NOTE]
随着 V0 引擎被弃用，类名和细节可能会发生变化。我将强调核心思想而不是确切的签名。我会抽象掉一些但不是所有的细节。</p>
</blockquote>
<p>Engine Core 本身由几个子组件组成：</p>
<ul>
<li><strong>Model Executor</strong>（驱动模型的前向传播，我们目前处理的是 <code>UniProcExecutor</code>，它在单个 GPU 上有一个 <code>Worker</code> 进程）。我们将逐步升级到支持多个 GPU 的 <code>MultiProcExecutor</code>。</li>
<li><strong>Structured Output Manager</strong>（用于 Guided Decoding - 我们稍后会介绍）</li>
<li><strong>Scheduler</strong>（决定哪些请求进入下一个引擎步骤）- 它进一步包含：<ul>
<li>策略设置 - 可以是 <strong>FCFS</strong>（先到先得）或 <strong>priority</strong>（高优先级的请求先被服务）</li>
<li><code>waiting</code> 和 <code>running</code> 队列</li>
<li><strong>KV Cache Manager</strong> - Paged Attention [3] 的核心</li>
</ul>
</li>
</ul>
<p>KV-cache 管理器维护一个 <code>free_block_queue</code> - 一个可用的 KV-cache 块池（通常有几十万个，取决于 VRAM 大小和块大小）。在 Paged Attention 期间，这些块作为索引结构，将 token 映射到其计算出的 KV cache 块。</p>
<p><img alt="图 1：本节描述的核心组件及其关系" src="Inside%20vLLM%20Anatomy%20of%20a%20High-Throughput%20LLM%20Inference%20System.assets/engine_constructor.png" /></p>
<blockquote>
<p>[!NOTE]对于一个标准的 Transformer 层（非 MLA [4]），块大小计算如下： 2 (key/value) <em><code>block_size</code> (默认=16)</em> <code>num_kv_heads</code> <em><code>head_size</code></em> <code>dtype_num_bytes</code> (例如 bf16 为 2)</p>
</blockquote>
<p>在 Model Executor 构建期间，会创建一个 <code>Worker</code> 对象，并执行三个关键过程。（稍后，使用 <code>MultiProcExecutor</code> 时，这些相同的过程会在不同 GPU 上的每个 worker 进程中独立运行。）</p>
<ol>
<li>
<p><strong>初始化设备</strong>：
    - 将 CUDA 设备（例如 "cuda:0"）分配给 worker 并检查模型数据类型是否受支持（例如 bf16）
    - 验证在给定的 <code>gpu_memory_utilization</code>（例如 0.8 -&gt; 80% 的总 VRAM）下是否有足够的 VRAM
    - 设置分布式设置（DP / TP / PP / EP 等）
    - 实例化一个 <code>model_runner</code>（包含采样器、KV cache 和前向传播缓冲区，如 <code>input_ids</code>、<code>positions</code> 等）
    - 实例化一个 <code>InputBatch</code> 对象（包含 CPU 端的前向传播缓冲区、用于 KV-cache 索引的块表、采样元数据等）</p>
</li>
<li>
<p><strong>加载模型</strong>：
    - 实例化模型架构
    - 加载模型权重
    - 调用 model.eval()（PyTorch 的推理模式）
    - 可选：在模型上调用 torch.compile()</p>
</li>
<li>
<p><strong>初始化 KV cache</strong>
    - 获取每层的 KV-cache 规范。以前这总是 <code>FullAttentionSpec</code>（同构 Transformer），但随着混合模型（滑动窗口、像 Jamba 这样的 Transformer/SSM）的出现，它变得更加复杂（参见 Jenga [5]）
    - 运行一个虚拟/性能分析的前向传播，并获取 GPU 内存快照，以计算可用 VRAM 中可以容纳多少 KV cache 块
    - 分配、重塑并将 KV cache 张量绑定到注意力层
    - 准备注意力元数据（例如将后端设置为 FlashAttention），稍后在 fwd pass 期间由 kernel 消耗
    - 除非提供了 <code>--enforce-eager</code>，否则对于每个预热批次大小，进行一次<strong>虚拟运行</strong>并捕获 CUDA graphs。CUDA graphs 将整个 GPU 工作序列记录到一个 DAG 中。稍后在 fwd pass 期间，我们启动/重放预先准备好的 graphs，从而减少 kernel 启动开销，进而提高延迟。</p>
</li>
</ol>
<p>我在这里抽象掉了许多底层细节——但这些是我现在要介绍的核心部分，因为我将在接下来的部分中反复引用它们。</p>
<p>现在我们已经初始化了引擎，让我们继续看 <code>generate</code> 函数。</p>
<h4 id="generate"><code>generate</code> 函数<a class="headerlink" href="#generate" title="Permanent link">&para;</a></h4>
<p>第一步是验证请求并将其输入引擎。对于每个prompt，我们：</p>
<ol>
<li>创建一个唯一的请求 ID 并捕获其到达时间</li>
<li>调用一个输入预处理器，对prompts进行分词并返回一个包含 <code>prompt</code>、<code>prompt_token_ids</code> 和 <code>type</code>（文本、token、嵌入等）的字典</li>
<li>将这些信息打包成一个 <code>EngineCoreRequest</code>，并添加优先级、采样参数和其他元数据</li>
<li>将请求传递到 Engine Core，Engine Core 将其包装在一个 <code>Request</code> 对象中，并将其状态设置为 <code>WAITING</code>。然后将此请求添加到调度程序的 <code>waiting</code> 队列中（如果是 FCFS 则追加，如果是优先级则push到堆中）</li>
</ol>
<p>此时，引擎已经接收了输入，可以开始执行。在同步引擎示例中，这些初始prompts是我们唯一要处理的——没有机制可以在运行中注入新的请求。相比之下，异步引擎支持这一点（也称为 <strong>continuous batching</strong> [6]）：在每个步骤之后，都会同时考虑新旧请求。</p>
<blockquote>
<p>[!NOTE]
因为前向传播将批次展平为单个序列，并且自定义 kernel 可以高效地处理它，所以即使在同步引擎中，continuous batching 也从根本上得到了支持。</p>
</blockquote>
<p>接下来，只要有请求需要处理，引擎就会重复调用其 <code>step()</code> 函数。每个步骤有三个阶段：</p>
<ol>
<li><strong>调度</strong>：选择在此步骤中运行的请求（decode 和/或 (chunked) prefill）</li>
<li><strong>前向传播</strong>：运行模型并采样 token</li>
<li><strong>后处理</strong>：将采样到的 token ID 附加到每个 <code>Request</code> 中，去分词，并检查停止条件。如果一个请求完成了，就进行清理（例如将其 KV-cache 块返回到 <code>free_block_queue</code>）并提前返回输出</li>
</ol>
<blockquote>
<p>[!NOTE]
停止条件是：</p>
<ul>
<li>请求超出了其长度限制（<code>max_model_length</code> 或其自身的 <code>max_tokens</code>）</li>
<li>采样到的 token 是 EOS ID（除非启用了 <code>ignore_eos</code> -&gt; 这在基准测试中很有用，当我们想要强制生成一定数量的输出 token 时）</li>
<li>采样到的 token 与采样参数中指定的任何 <code>stop_token_ids</code> 匹配</li>
<li>输出中存在停止字符串 - 我们将输出截断到第一个停止字符串出现的位置，并在引擎中中止该请求（注意 <code>stop_token_ids</code> 会出现在输出中，但停止字符串不会）。
</li>
</ul>
</blockquote>
<p><img alt="图 2：引擎循环" src="Inside%20vLLM%20Anatomy%20of%20a%20High-Throughput%20LLM%20Inference%20System.assets/engine_loop.png" /></p>
<blockquote>
<p>[!NOTE]
在流式模式下，我们会在生成 token 时发送中间 token，但我们现在先忽略这一点。</p>
</blockquote>
<p>接下来，我们将更详细地研究调度。</p>
<h4 id="_1">调度器<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h4>
<p>推理引擎处理两种主要类型的工作负载：</p>
<ol>
<li><strong>Prefill</strong> 请求 — 对所有prompt token 进行一次前向传播。这些通常是<strong>计算密集型</strong>的（阈值取决于硬件和prompt长度）。最后，我们从最后一个 token 位置的概率分布中采样一个 token。</li>
<li><strong>Decode</strong> 请求 — 仅对最新的一个 token 进行一次前向传播。所有早期的 KV 向量都已经被缓存。这些是<strong>内存带宽密集型</strong>的，因为我们仍然需要加载所有 LLM 权重（和 KV caches）才能计算一个 token。</li>
</ol>
<blockquote>
<p>[!NOTE]
在<a href="#基准测试和自动调优-延迟vs吞吐量">基准测试部分</a>，我们将分析所谓的 GPU 性能的 roofline 模型。这将更详细地探讨 prefill/decode 的性能概况。</p>
</blockquote>
<p>V1 调度器可以在同一步骤中混合这两种类型的请求，这要归功于更智能的设计选择。相比之下，V0 引擎一次只能处理 prefill 或 decode。</p>
<p>调度器优先处理 decode 请求——即那些已经在 <code>running</code> 队列中的请求。对于每个这样的请求，它：</p>
<ol>
<li>计算要生成的新 token 的数量（由于 speculative decoding 和异步调度，不总是 1——稍后会详细介绍）。</li>
<li>调用 KV-cache 管理器的 <code>allocate_slots</code> 函数（详见下文）。</li>
<li>通过从第 1 步的 token 数量中减去来更新 token 预算。</li>
</ol>
<p>之后，它处理来自 <code>waiting</code> 队列的 prefill 请求，它：</p>
<ol>
<li>检索已计算块的数量（如果禁用了 prefix caching，则返回 0——我们稍后会介绍）。</li>
<li>调用 KV-cache 管理器的 <code>allocate_slots</code> 函数。</li>
<li>从 waiting 队列中弹出请求并将其移动到 running 队列，将其状态设置为 <code>RUNNING</code>。</li>
<li>更新 token 预算。</li>
</ol>
<p>现在让我们看看 <code>allocate_slots</code> 做了什么，它：</p>
<ol>
<li><strong>计算块数</strong> — 确定必须分配多少个新的 KV-cache 块 (<code>n</code>)。每个块默认存储 16 个 token。例如，如果一个 prefill 请求有 17 个新 token，我们需要 <code>ceil(17/16) = 2</code> 个块。</li>
<li><strong>检查可用性</strong> — 如果管理器池中没有足够的块，则<strong>提前退出</strong>。根据是 decode 还是 prefill 请求，引擎可能会尝试重新计算抢占（V0 中支持交换抢占），方法是驱逐低优先级请求（调用 <code>kv_cache_manager.free</code> 将 KV 块返回到块池），或者它可能会跳过调度并继续执行。</li>
<li><strong>分配块</strong> — 通过 KV-cache 管理器的协调器，从块池（前面提到的 <code>free_block_queue</code> 双向链表）中获取前 <code>n</code> 个块。存储到 <code>req_to_blocks</code>，这是一个将每个 <code>request_id</code> 映射到其 KV-cache 块列表的字典。</li>
</ol>
<p><img alt="图 3：KV cache 块列表" src="Inside%20vLLM%20Anatomy%20of%20a%20High-Throughput%20LLM%20Inference%20System.assets/kv_cache_blocks.png" /></p>
<p>我们终于准备好进行一次前向传播了！</p>
<h4 id="_2">运行前向传播<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h4>
<p>我们调用 Model Executor 的 <code>execute_model</code>，它委托给 <code>Worker</code>，而 <code>Worker</code> 又委托给model runner。</p>
<p>以下是主要步骤：</p>
<ol>
<li><strong>更新状态</strong> — 从 <code>input_batch</code> 中修剪已完成的请求；更新与 fwd pass 相关的杂项元数据（例如，每个请求的 KV cache 块，将用于索引到 paged KV cache 内存中）。</li>
<li><strong>准备输入</strong> — 将缓冲区从 CPU 复制到 GPU；计算位置；构建 <code>slot_mapping</code>（示例中会详细介绍）；构造注意力元数据。</li>
<li><strong>前向传播</strong> — 使用自定义的 paged attn kernel 运行模型。所有序列都被展平并连接成一个长的“超级序列”。位置索引和注意力掩码确保每个序列只关注自己的 token，这使得 continuous batching 无需右填充。</li>
<li><strong>收集最后一个 token 的状态</strong> — 提取每个序列最后一个位置的隐藏状态并计算 logits。</li>
<li><strong>采样</strong> — 根据采样配置（贪婪、温度、top-p、top-k 等）从计算出的 logits 中采样 token。</li>
</ol>
<p>前向传播步骤本身有两种执行模式：</p>
<ol>
<li><strong>Eager 模式</strong> — 启用 eager execution 时运行标准的 PyTorch 前向传播。</li>
<li><strong>“捕获”模式</strong> — 当不强制执行 eager 时，执行/重放预先捕获的 CUDA Graph（请记住，我们在引擎构建期间的初始化 KV cache 过程中捕获了这些）。</li>
</ol>
<p>这里有一个具体的例子，应该可以清楚地说明 continuous batching 和 paged attention：
<img alt="图 4：前向传播：continuous batching 和 paged attention" src="Inside%20vLLM%20Anatomy%20of%20a%20High-Throughput%20LLM%20Inference%20System.assets/fwd_pass.png" />
slot_mapping: 将逻辑的token id映射到实际的KVCache的物理槽位(slot)位置</p>
<h3 id="_3">高级功能 — 扩展核心引擎逻辑<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h3>
<p>掌握了基本的引擎流程后，我们现在可以看看高级功能。</p>
<p>我们已经讨论了抢占、Paged Attention 和 Continuous Batching。</p>
<p>接下来，我们将深入探讨：</p>
<ol>
<li>Chunked Prefill</li>
<li>Prefix Caching</li>
<li>Guided Decoding（通过基于语法的有限状态机）</li>
<li>Speculative Decoding</li>
<li>Disaggregated P/D (prefill/decoding)</li>
</ol>
<h4 id="chunked-prefill">Chunked Prefill<a class="headerlink" href="#chunked-prefill" title="Permanent link">&para;</a></h4>
<p>Chunked Prefill 是一种通过将其 prefill 步骤拆分成更小的块来处理长prompt的技术。如果没有它，我们可能会遇到单个非常长的请求独占一个引擎步骤，从而阻止其他 prefill 请求运行的情况。这会推迟所有其他请求并增加它们的延迟。</p>
<p>例如，让每个块包含 <code>n</code> (=8) 个 token，用小写字母标记，并用“-”分隔。一个长prompt <code>P</code> 可能看起来像 <code>x-y-z</code>，其中 <code>z</code> 是一个不完整的块（例如 2 个 token）。执行 <code>P</code> 的完整 prefill 将需要 ≥ 3 个引擎步骤（如果它在其中一个步骤中没有被调度执行，则可能 &gt; 3），并且只有在最后一个 chunked prefill 步骤中我们才会采样一个新的 token。</p>
<p>这是同一个例子的图示：</p>
<p><img alt="图 5：Chunked Prefill" src="Inside%20vLLM%20Anatomy%20of%20a%20High-Throughput%20LLM%20Inference%20System.assets/chunked_pt1.png" /></p>
<p>实现很简单：限制每个步骤的新 token 数量。如果请求的数量超过 <code>long_prefill_token_threshold</code>，则将其重置为该确切值。底层的索引逻辑（前面描述的）会处理剩下的事情。</p>
<p>在 vLLM V1 中，您可以通过将 <code>long_prefill_token_threshold</code> 设置为正整数来启用 chunked prefill。（技术上讲，无论如何都可能发生，如果prompt长度超过了 token 预算，我们会截断它并运行 chunked prefill。）</p>
<h4 id="prefix-caching">Prefix Caching<a class="headerlink" href="#prefix-caching" title="Permanent link">&para;</a></h4>
<p>为了解释 prefix caching 的工作原理，让我们对原始代码示例稍作调整：</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">vllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLM</span><span class="p">,</span> <span class="n">SamplingParams</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="n">long_prefix</span> <span class="o">=</span> <span class="s2">&quot;&lt;a piece of text that is encoded into more than block_size tokens&gt;&quot;</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>    <span class="s2">&quot;Hello, my name is&quot;</span><span class="p">,</span>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>    <span class="s2">&quot;The president of the United States is&quot;</span><span class="p">,</span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a><span class="p">]</span>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a><span class="n">sampling_params</span> <span class="o">=</span> <span class="n">SamplingParams</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a><span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">():</span>
</span><span id="__span-1-13"><a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>    <span class="n">llm</span> <span class="o">=</span> <span class="n">LLM</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;TinyLlama/TinyLlama-1.1B-Chat-v1.0&quot;</span><span class="p">)</span>
</span><span id="__span-1-14"><a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a>
</span><span id="__span-1-15"><a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a>    <span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">long_prefix</span> <span class="o">+</span> <span class="n">prompts</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">sampling_params</span><span class="p">)</span>
</span><span id="__span-1-16"><a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a>    <span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">long_prefix</span> <span class="o">+</span> <span class="n">prompts</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">sampling_params</span><span class="p">)</span>
</span><span id="__span-1-17"><a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a>
</span><span id="__span-1-18"><a id="__codelineno-1-18" name="__codelineno-1-18" href="#__codelineno-1-18"></a><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
</span><span id="__span-1-19"><a id="__codelineno-1-19" name="__codelineno-1-19" href="#__codelineno-1-19"></a>    <span class="n">main</span><span class="p">()</span>
</span></code></pre></div>
<p>Prefix caching 避免了重新计算多个prompt在开头共享的 token——因此得名 <strong>prefix</strong>。</p>
<p>关键部分是 <code>long_prefix</code>：它被定义为任何长于一个 KV-cache 块（默认为 16 个 token）的前缀。为了简化我们的示例，我们假设 <code>long_prefix</code> 的长度正好是 <code>n x block_size</code>（其中 <code>n ≥ 1</code>）。</p>
<blockquote>
<p>[!NOTE]
即它与块边界完美对齐——否则我们将不得不重新计算 <code>long_prefix_len % block_size</code> 个 token，因为我们无法缓存不完整的块。</p>
<p>Q: 那如果没有对齐, 是选择空出block, 还是每次拼接后都重算呢?</p>
</blockquote>
<p>如果没有 prefix caching，每次我们处理一个具有相同 <code>long_prefix</code> 的新请求时，我们都会重新计算所有 <code>n x block_size</code> 个 token。</p>
<p>有了 prefix caching，这些 token 只计算一次（它们的 KV 存储在 KV cache paged memory 中），然后被重用，所以只需要处理新的prompt token。这加快了 prefill 请求的速度（尽管对 decode 没有帮助）。</p>
<p>这在 vLLM 中是如何工作的？</p>
<p>在第一次 <code>generate</code> 调用期间，在调度阶段，在 <code>kv_cache_manager.get_computed_blocks</code> 内部，引擎调用 <code>hash_request_tokens</code>：</p>
<ol>
<li>
<p>此函数将 <code>long_prefix + prompts[0]</code> 拆分成 16 个 token 的块。</p>
</li>
<li>
<p>对于每个完整的块，它计算一个哈希（使用内置哈希或 SHA-256，后者较慢但冲突较少）。该哈希结合了<strong>前一个块的哈希</strong>、<strong>当前 token</strong> 和可选的<strong>元数据</strong>。</p>
</li>
</ol>
<blockquote>
<p>[!NOTE]
可选的元数据包括：</p>
<ul>
<li>MM hash: <strong>Multi-Model Hash 多模态Hash</strong>, 组合图片和文本进行特征编码, 得到总体的Hash</li>
<li>LoRA ID: <strong>Low-Rank Adapter</strong>, 使用不同的低秩矩阵进行参数微调, 实现模型定制和任务迁移</li>
<li>cache salt: 注入到<strong>第一个块</strong>的哈希中，确保只有具有此缓存盐的请求才能重用块</li>
</ul>
</blockquote>
<ol>
<li>每个结果都存储为一个 <code>BlockHash</code> 对象，包含哈希及其 token ID。我们返回一个块哈希列表。</li>
</ol>
<p>该列表存储在 <code>self.req_to_block_hashes[request_id]</code> 中。</p>
<p>接下来，引擎调用 <code>find_longest_cache_hit</code> 来检查这些block hash中是否有任何一个已经存在于 <code>cached_block_hash_to_block</code> 中。在此处的第一个请求上，没有找到命中。</p>
<p><img alt="图 6：Prefix caching - 哈希函数" src="Inside%20vLLM%20Anatomy%20of%20a%20High-Throughput%20LLM%20Inference%20System.assets/prefix_pt1.png" /></p>
<p>然后我们调用 <code>allocate_slots</code>，它调用 <code>coordinator.cache_blocks</code>，将新的 <code>BlockHash</code> 条目与分配的 KV 块关联起来，并将它们记录在 <code>cached_block_hash_to_block</code> 中。</p>
<p>之后，前向传播将在 paged KV cache 内存中填充与我们上面分配的 KV cache 块相对应的 KV。</p>
<blockquote>
<p>[!NOTE]
经过许多引擎步骤后，它会分配更多的 KV cache 块，但这对于我们的示例来说无关紧要，因为前缀在 <code>long_prefix</code> 之后立即分叉了。</p>
</blockquote>
<p><img alt="图 7：Prefix caching - 在 paged memory 中填充 KV" src="Inside%20vLLM%20Anatomy%20of%20a%20High-Throughput%20LLM%20Inference%20System.assets/prefix_pt2.png" /></p>
<p>在第二次使用相同前缀的 <code>generate</code> 调用中，重复步骤 1-3，但现在 <code>find_longest_cache_hit</code> 为所有 <code>n</code> 个块找到匹配项（通过线性搜索）。引擎可以直接重用这些 KV 块。</p>
<p><img alt="图 8：Prefix caching - 重用 KV" src="Inside%20vLLM%20Anatomy%20of%20a%20High-Throughput%20LLM%20Inference%20System.assets/prefix_pt3.png" /></p>
<p>如果原始请求仍然存在，这些块的引用计数将增加（例如增加到 2）。在这个例子中，第一个请求已经完成，所以这些块被释放回池中，它们的引用计数被重置为 0。因为我们能够从 <code>cached_block_hash_to_block</code> 中检索到它们，我们知道它们是有效的（KV cache 管理器的逻辑是这样设置的），所以我们只是再次将它们从 <code>free_block_queue</code> 中移除。</p>
<blockquote>
<p>[!NOTE] Advanced note:
KV-cache 块只有在它们即将从 <code>free_block_queue</code>（从左侧弹出）重新分配时才会失效，并且我们发现该块仍然具有关联的哈希并且存在于 <code>cached_block_hash_to_block</code> 中。在那一刻，我们清除该块的哈希并将其条目从 <code>cached_block_hash_to_block</code> 中移除，确保它不能通过 prefix caching 重用（至少不能用于那个旧前缀）。</p>
</blockquote>
<p>这就是 prefix caching 的要点：不要重新计算你已经见过的 prefixes——只需重用它们的 KV cache！</p>
<p>如果你理解了这个例子，你也就理解了 paged attention 的工作原理。</p>
<p>Prefix caching 默认启用。要禁用它：<code>enable_prefix_caching = False</code>。</p>
<h4 id="guided-decoding-fsm">Guided Decoding (FSM)<a class="headerlink" href="#guided-decoding-fsm" title="Permanent link">&para;</a></h4>
<p>Guided decoding 是一种技术，在每个 decoding 步骤中，logits 都受到基于语法的有限状态机的约束。<strong>这确保了只有语法允许的 token 才能被采样。</strong></p>
<p>这是一个强大的设置：你可以强制执行从正则语法（Chomsky type-3，例如任意正则表达式模式）到上下文无关语法（type-2，涵盖大多数编程语言）的任何内容。</p>
<p>为了让这不那么抽象，让我们从最简单的例子开始，在我们早期的代码上构建：</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">vllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLM</span><span class="p">,</span> <span class="n">SamplingParams</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">vllm.sampling_params</span><span class="w"> </span><span class="kn">import</span> <span class="n">GuidedDecodingParams</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>    <span class="s2">&quot;This sucks&quot;</span><span class="p">,</span>
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>    <span class="s2">&quot;The weather is beautiful&quot;</span><span class="p">,</span>
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a><span class="p">]</span>
</span><span id="__span-2-8"><a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a>
</span><span id="__span-2-9"><a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a><span class="n">guided_decoding_params</span> <span class="o">=</span> <span class="n">GuidedDecodingParams</span><span class="p">(</span><span class="n">choice</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Positive&quot;</span><span class="p">,</span> <span class="s2">&quot;Negative&quot;</span><span class="p">])</span>
</span><span id="__span-2-10"><a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a><span class="n">sampling_params</span> <span class="o">=</span> <span class="n">SamplingParams</span><span class="p">(</span><span class="n">guided_decoding</span><span class="o">=</span><span class="n">guided_decoding_params</span><span class="p">)</span>
</span><span id="__span-2-11"><a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a>
</span><span id="__span-2-12"><a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a><span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">():</span>
</span><span id="__span-2-13"><a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a>    <span class="n">llm</span> <span class="o">=</span> <span class="n">LLM</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;TinyLlama/TinyLlama-1.1B-Chat-v1.0&quot;</span><span class="p">)</span>
</span><span id="__span-2-14"><a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a>
</span><span id="__span-2-15"><a id="__codelineno-2-15" name="__codelineno-2-15" href="#__codelineno-2-15"></a>    <span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>
</span><span id="__span-2-16"><a id="__codelineno-2-16" name="__codelineno-2-16" href="#__codelineno-2-16"></a>
</span><span id="__span-2-17"><a id="__codelineno-2-17" name="__codelineno-2-17" href="#__codelineno-2-17"></a><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
</span><span id="__span-2-18"><a id="__codelineno-2-18" name="__codelineno-2-18" href="#__codelineno-2-18"></a>    <span class="n">main</span><span class="p">()</span>
</span></code></pre></div>
<p>在我给出的玩具示例中（假设是字符级分词）：在 prefill 时，FSM 会屏蔽 logits，因此只有“P”或“N”是可行的。如果采样到“P”，FSM 会移动到“Positive”分支；下一步只允许“o”，依此类推。</p>
<p><img alt="图 9：玩具示例 FSM" src="Inside%20vLLM%20Anatomy%20of%20a%20High-Throughput%20LLM%20Inference%20System.assets/fsm.png" /></p>
<p>这在 vLLM 中是如何工作的：</p>
<ol>
<li>在 LLM 引擎构建时，会创建一个 <code>StructuredOutputManager</code>；它可以访问 tokenizer 并维护一个 <code>_grammar_bitmask</code> 张量。</li>
<li>添加请求时，其状态设置为 <code>WAITING_FOR_FSM</code>，<code>grammar_init</code> 选择后端编译器（例如，<code>xgrammar</code> [7]；注意后端是第三方代码）。</li>
<li>此请求的语法是异步编译的。</li>
<li>在调度期间，如果异步编译已完成，状态将切换到 <code>WAITING</code>，并将 <code>request_id</code> 添加到 <code>structured_output_request_ids</code>；否则将其放入 <code>skipped_waiting_requests</code> 以在下一个引擎步骤中重试。</li>
<li>在调度循环之后（仍在调度内部），如果有 FSM 请求，<code>StructuredOutputManager</code> 会要求后端准备/更新 <code>_grammar_bitmask</code>。</li>
<li>在前向传播产生 logits 之后，xgr_torch_compile 的函数将位掩码扩展到词汇表大小（使用 32 位整数时扩展比为 32x）并将不允许的 logits 屏蔽为 –∞。</li>
<li>采样下一个 token 后，通过 <code>accept_tokens</code> 推进请求的 FSM。在 FSM 图上，我们视觉上移动到下一个状态。</li>
</ol>
<p>第 6 步值得进一步说明。</p>
<p>如果 <code>vocab_size = 32</code>，<code>_grammar_bitmask</code> 是一个整数；其二进制表示编码了哪些 token 是允许的（“1”）与不允许的（“0”）。例如，“101…001”扩展为一个长度为 32 的数组 <code>[1, 0, 1, ..., 0, 0, 1]</code>；位置为 0 的 logits 被设置为 –∞。对于更大的词汇表，使用多个 32 位字并相应地扩展/连接。后端（例如，<code>xgrammar</code>）负责使用当前的 FSM 状态生成这些位模式。</p>
<blockquote>
<p>[!NOTE]
这里的大部分复杂性都隐藏在像 xgrammar 这样的第三方库中。</p>
</blockquote>
<p>这是一个更简单的例子，词汇表大小为 8，使用 8 位整数（对于那些喜欢我的图示的人）：</p>
<p><img alt="图 10：玩具示例" src="Inside%20vLLM%20Anatomy%20of%20a%20High-Throughput%20LLM%20Inference%20System.assets/fsm2.png" /></p>
<p>您可以在 vLLM 中通过传入所需的 <code>guided_decoding</code> 配置来启用此功能。</p>
<h4 id="speculative-decoding">Speculative Decoding<a class="headerlink" href="#speculative-decoding" title="Permanent link">&para;</a></h4>
<p>在自回归生成中，每个新 token 都需要对大型 LM 进行一次前向传播。这很昂贵——每一步都要重新加载和应用所有模型权重，只为了计算一个 token！（假设 batch size == 1，通常是 <code>B</code>）</p>
<p>Speculative decoding(投机解码) [8] 通过引入一个较小的 draft LM 来加速这一过程。draft LM 可以廉价地提出 <em>(未来连续的)</em> <code>k</code> 个 token。但我们最终不想从较小的模型中采样——它只是用来猜测候选的延续。大型模型仍然决定什么是有效的。</p>
<p>以下是步骤：</p>
<ol>
<li><strong>Draft</strong>：在当前上下文中运行小型模型并提出 <code>k</code> 个 token</li>
<li><strong>Verify</strong>：在上下文 + <code>k</code> 个 draft token 上运行一次大型模型。这将为这 <code>k</code> 个位置加上一个额外的位置产生概率（所以我们得到 <code>k+1</code> 个候选）</li>
<li><strong>Accept/reject</strong>：从左到右遍历 <code>k</code> 个 draft token：
    - 如果大型模型对 draft token 的概率 ≥ draft 模型的概率，则接受它
    - 否则，以 <code>p_large(token)/p_draft(token)</code> 的概率接受它
    - 在第一次拒绝时停止，或接受所有 <code>k</code> 个 draft token
        - 如果所有 <code>k</code> 个 draft token 都被接受，也从大型模型中“免费”采样额外的第 <code>(k+1)</code> 个 token（我们已经计算了该分布）
        - 如果发生拒绝，则在该位置创建一个新的重新平衡的分布（<code>p_large - p_draft</code>，将最小值钳位在 0，归一化以使总和为 1）并从中采样最后一个 token
        - 注:
         - 发生reject意味着Draft LM已经占据了概率质量, 需要在剩余的概率空间(<code>p_large - p_draft</code>)中采样
         - 每个p都是vocab size维的概率向量</li>
</ol>
<p><strong>为什么这行得通</strong>：虽然我们使用小型模型来提出候选，但接受/拒绝规则保证了序列在期望上与我们逐个 token 从大型模型中采样完全相同。这意味着 speculative decoding 在统计上等同于标准的自回归 decoding——但可能快得多，因为一次大型模型的前向传播最多可以产生 <code>k+1</code> 个 token。</p>
<blockquote>
<p>[!NOTE]
我建议查看 <a href="https://github.com/meta-pytorch/gpt-fast" title="null">gpt-fast</a> 以获取简单的实现，以及<a href="https://arxiv.org/abs/2302.01318" title="null">原始论文</a>以了解数学细节和与从完整模型采样等效的证明。</p>
</blockquote>
<p>vLLM V1 不支持 LLM draft model 方法，而是实现了更快但不太准确的提议方案：n-gram、EAGLE [9] 和 Medusa [10]。</p>
<p>每个方案的一句话总结：</p>
<ul>
<li><strong>n-gram</strong>：取最后 <code>prompt_lookup_max</code> 个 token；在序列中找到一个先前的匹配项；如果找到，则提出该匹配项后面的 <code>k</code> 个 token；否则减少窗口并重试直到 <code>prompt_lookup_min</code></li>
</ul>
<blockquote>
<p>[!NOTE]
当前的实现返回第一个匹配项后的 <code>k</code> 个 token。引入一个近因偏见并反转搜索方向似乎更自然？（即最后一个匹配项）</p>
</blockquote>
<ul>
<li><strong>Eagle</strong>：对大型 LM 进行“模型手术”——保留 embeddings 和 LM head，用一个轻量级的 MLP 替换 Transformer 堆栈；将其微调为一个廉价的 draft</li>
<li><strong>Medusa</strong>：在大型模型的顶部（LM head 之前的 embeddings）训练辅助线性头，以并行预测接下来的 <code>k</code> 个 token；使用这些头比运行一个单独的小型 LM 更有效地提出 token</li>
</ul>
<p>以下是如何在 vLLM 中使用 <code>ngram</code> 作为 draft 方法来调用 speculative decoding：</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">vllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLM</span><span class="p">,</span> <span class="n">SamplingParams</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>    <span class="s2">&quot;Hello, my name is&quot;</span><span class="p">,</span>
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>    <span class="s2">&quot;The president of the United States is&quot;</span><span class="p">,</span>
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a><span class="p">]</span>
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a><span class="n">sampling_params</span> <span class="o">=</span> <span class="n">SamplingParams</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>
</span><span id="__span-3-10"><a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a><span class="n">speculative_config</span><span class="o">=</span><span class="p">{</span>
</span><span id="__span-3-11"><a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>    <span class="s2">&quot;method&quot;</span><span class="p">:</span> <span class="s2">&quot;ngram&quot;</span><span class="p">,</span>
</span><span id="__span-3-12"><a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a>    <span class="s2">&quot;prompt_lookup_max&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
</span><span id="__span-3-13"><a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>    <span class="s2">&quot;prompt_lookup_min&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
</span><span id="__span-3-14"><a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a>    <span class="s2">&quot;num_speculative_tokens&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
</span><span id="__span-3-15"><a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a><span class="p">}</span>
</span><span id="__span-3-16"><a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a>
</span><span id="__span-3-17"><a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a><span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">():</span>
</span><span id="__span-3-18"><a id="__codelineno-3-18" name="__codelineno-3-18" href="#__codelineno-3-18"></a>    <span class="n">llm</span> <span class="o">=</span> <span class="n">LLM</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;TinyLlama/TinyLlama-1.1B-Chat-v1.0&quot;</span><span class="p">,</span> <span class="n">speculative_config</span><span class="o">=</span><span class="n">speculative_config</span><span class="p">)</span>
</span><span id="__span-3-19"><a id="__codelineno-3-19" name="__codelineno-3-19" href="#__codelineno-3-19"></a>
</span><span id="__span-3-20"><a id="__codelineno-3-20" name="__codelineno-3-20" href="#__codelineno-3-20"></a>    <span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>
</span><span id="__span-3-21"><a id="__codelineno-3-21" name="__codelineno-3-21" href="#__codelineno-3-21"></a>
</span><span id="__span-3-22"><a id="__codelineno-3-22" name="__codelineno-3-22" href="#__codelineno-3-22"></a><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
</span><span id="__span-3-23"><a id="__codelineno-3-23" name="__codelineno-3-23" href="#__codelineno-3-23"></a>    <span class="n">main</span><span class="p">()</span>
</span></code></pre></div>
<p>这在 vLLM 中是如何工作的？</p>
<p><strong>设置（在引擎构建期间）：</strong></p>
<ol>
<li>初始化设备：创建一个 <code>drafter</code>（draft model，例如，<code>NgramProposer</code>）和一个 <code>rejection_sampler</code>（其部分是用 Triton 编写的）。</li>
<li>加载模型：加载 draft model 权重（对于 n-gram 是无操作）。</li>
</ol>
<p><strong>之后在 <code>generate</code> 函数中</strong>（假设我们得到一个全新的请求）：</p>
<ol>
<li>使用大型模型运行常规的 prefill 步骤。</li>
<li>在前向传播和标准采样之后，调用 <code>propose_draft_token_ids(k)</code> 从 draft model 中采样 <code>k</code> 个 draft token。</li>
<li>将这些存储在 <code>request.spec_token_ids</code> 中（更新请求元数据）。</li>
<li>在下一个引擎步骤中，当请求在 running 队列中时，将 <code>len(request.spec_token_ids)</code> 添加到“新 token”计数中，以便 <code>allocate_slots</code> 为 fwd pass 保留足够的 KV 块。</li>
<li>将 <code>spec_token_ids</code> 复制到 <code>input_batch.token_ids_cpu</code> 中以形成（上下文 + draft）token。</li>
<li>通过 <code>_calc_spec_decode_metadata</code> 计算元数据（这将从 <code>input_batch.token_ids_cpu</code> 复制 token，准备 logits 等），然后在 draft token 上运行大型模型的前向传播。</li>
<li>不从 logits 进行常规采样，而是使用 <code>rejection_sampler</code> 从左到右接受/拒绝并产生 <code>output_token_ids</code>。</li>
<li>重复步骤 2-7 直到满足停止条件。</li>
</ol>
<p>内化这一点的最佳方法是启动调试器并单步执行代码库，但希望本节能让您对此有所了解。这个也是：</p>
<p><img alt="图 11：Speculative Decoding" src="Inside%20vLLM%20Anatomy%20of%20a%20High-Throughput%20LLM%20Inference%20System.assets/specdec_pt1.png" /></p>
<h4 id="disaggregated-pd">Disaggregated P/D<a class="headerlink" href="#disaggregated-pd" title="Permanent link">&para;</a></h4>
<p>我之前已经暗示了 disaggregated P/D (prefill/decode) 背后的动机。</p>
<p>Prefill 和 decode 具有非常不同的性能概况（计算密集型 vs. 内存带宽密集型），因此将它们的执行分开是一种明智的设计。它对延迟提供了更严格的控制——包括 <code>TFTT</code>（首个 token 时间）和 <code>ITL</code>（token 间延迟）——更多内容将在<a href="#基准测试和自动调优-延迟vs吞吐量">基准测试</a>部分讨论。</p>
<p>在实践中，我们运行 <code>N</code> 个 vLLM prefill 实例和 <code>M</code> 个 vLLM decode 实例，并根据实时请求组合自动扩展它们。Prefill worker 将 KV 写入专用的 KV-cache 服务；decode worker 从中读取。这将长的、突发性的 prefill 与稳定的、对延迟敏感的 decode 隔离开来。</p>
<p>这在 vLLM 中是如何工作的？</p>
<p>为清楚起见，下面的示例依赖于 <code>SharedStorageConnector</code>，这是一个用于说明机制的调试连接器实现。</p>
<blockquote>
<p>[!NOTE]
Connector 是 vLLM 用于处理实例之间 KV 交换的抽象。Connector 接口尚不稳定，计划在近期进行一些改进，其中将涉及一些更改，其中一些可能是破坏性的。</p>
</blockquote>
<p>我们启动 2 个 vLLM 实例（GPU 0 用于 prefill，GPU 1 用于 decode），然后在它们之间传输 KV cache：</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">multiprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Event</span><span class="p">,</span> <span class="n">Process</span>
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span class="kn">import</span><span class="w"> </span><span class="nn">multiprocessing</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">mp</span>
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a><span class="kn">from</span><span class="w"> </span><span class="nn">vllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLM</span><span class="p">,</span> <span class="n">SamplingParams</span>
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a><span class="kn">from</span><span class="w"> </span><span class="nn">vllm.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">KVTransferConfig</span>
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>
</span><span id="__span-4-9"><a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a><span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-4-10"><a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a>    <span class="s2">&quot;Hello, my name is&quot;</span><span class="p">,</span>
</span><span id="__span-4-11"><a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>    <span class="s2">&quot;The president of the United States is&quot;</span><span class="p">,</span>
</span><span id="__span-4-12"><a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a><span class="p">]</span>
</span><span id="__span-4-13"><a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a>
</span><span id="__span-4-14"><a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a><span class="k">def</span><span class="w"> </span><span class="nf">run_prefill</span><span class="p">(</span><span class="n">prefill_done</span><span class="p">):</span>
</span><span id="__span-4-15"><a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a>  <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;0&quot;</span>
</span><span id="__span-4-16"><a id="__codelineno-4-16" name="__codelineno-4-16" href="#__codelineno-4-16"></a>
</span><span id="__span-4-17"><a id="__codelineno-4-17" name="__codelineno-4-17" href="#__codelineno-4-17"></a>  <span class="n">sampling_params</span> <span class="o">=</span> <span class="n">SamplingParams</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-4-18"><a id="__codelineno-4-18" name="__codelineno-4-18" href="#__codelineno-4-18"></a>
</span><span id="__span-4-19"><a id="__codelineno-4-19" name="__codelineno-4-19" href="#__codelineno-4-19"></a>  <span class="n">ktc</span><span class="o">=</span><span class="n">KVTransferConfig</span><span class="p">(</span>
</span><span id="__span-4-20"><a id="__codelineno-4-20" name="__codelineno-4-20" href="#__codelineno-4-20"></a>      <span class="n">kv_connector</span><span class="o">=</span><span class="s2">&quot;SharedStorageConnector&quot;</span><span class="p">,</span>
</span><span id="__span-4-21"><a id="__codelineno-4-21" name="__codelineno-4-21" href="#__codelineno-4-21"></a>      <span class="n">kv_role</span><span class="o">=</span><span class="s2">&quot;kv_both&quot;</span><span class="p">,</span>
</span><span id="__span-4-22"><a id="__codelineno-4-22" name="__codelineno-4-22" href="#__codelineno-4-22"></a>      <span class="n">kv_connector_extra_config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;shared_storage_path&quot;</span><span class="p">:</span> <span class="s2">&quot;local_storage&quot;</span><span class="p">},</span>
</span><span id="__span-4-23"><a id="__codelineno-4-23" name="__codelineno-4-23" href="#__codelineno-4-23"></a>  <span class="p">)</span>
</span><span id="__span-4-24"><a id="__codelineno-4-24" name="__codelineno-4-24" href="#__codelineno-4-24"></a>
</span><span id="__span-4-25"><a id="__codelineno-4-25" name="__codelineno-4-25" href="#__codelineno-4-25"></a>  <span class="n">llm</span> <span class="o">=</span> <span class="n">LLM</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;TinyLlama/TinyLlama-1.1B-Chat-v1.0&quot;</span><span class="p">,</span> <span class="n">kv_transfer_config</span><span class="o">=</span><span class="n">ktc</span><span class="p">)</span>
</span><span id="__span-4-26"><a id="__codelineno-4-26" name="__codelineno-4-26" href="#__codelineno-4-26"></a>  <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>
</span><span id="__span-4-27"><a id="__codelineno-4-27" name="__codelineno-4-27" href="#__codelineno-4-27"></a>
</span><span id="__span-4-28"><a id="__codelineno-4-28" name="__codelineno-4-28" href="#__codelineno-4-28"></a>  <span class="n">prefill_done</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>  <span class="c1"># notify decode instance that KV cache is ready</span>
</span><span id="__span-4-29"><a id="__codelineno-4-29" name="__codelineno-4-29" href="#__codelineno-4-29"></a>
</span><span id="__span-4-30"><a id="__codelineno-4-30" name="__codelineno-4-30" href="#__codelineno-4-30"></a>  <span class="c1"># To keep the prefill node running in case the decode node is not done;</span>
</span><span id="__span-4-31"><a id="__codelineno-4-31" name="__codelineno-4-31" href="#__codelineno-4-31"></a>  <span class="c1"># otherwise, the script might exit prematurely, causing incomplete decoding.</span>
</span><span id="__span-4-32"><a id="__codelineno-4-32" name="__codelineno-4-32" href="#__codelineno-4-32"></a>  <span class="k">try</span><span class="p">:</span>
</span><span id="__span-4-33"><a id="__codelineno-4-33" name="__codelineno-4-33" href="#__codelineno-4-33"></a>      <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span><span id="__span-4-34"><a id="__codelineno-4-34" name="__codelineno-4-34" href="#__codelineno-4-34"></a>          <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-4-35"><a id="__codelineno-4-35" name="__codelineno-4-35" href="#__codelineno-4-35"></a>  <span class="k">except</span> <span class="ne">KeyboardInterrupt</span><span class="p">:</span>
</span><span id="__span-4-36"><a id="__codelineno-4-36" name="__codelineno-4-36" href="#__codelineno-4-36"></a>      <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Script stopped by user.&quot;</span><span class="p">)</span>
</span><span id="__span-4-37"><a id="__codelineno-4-37" name="__codelineno-4-37" href="#__codelineno-4-37"></a>
</span><span id="__span-4-38"><a id="__codelineno-4-38" name="__codelineno-4-38" href="#__codelineno-4-38"></a><span class="k">def</span><span class="w"> </span><span class="nf">run_decode</span><span class="p">(</span><span class="n">prefill_done</span><span class="p">):</span>
</span><span id="__span-4-39"><a id="__codelineno-4-39" name="__codelineno-4-39" href="#__codelineno-4-39"></a>  <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span>
</span><span id="__span-4-40"><a id="__codelineno-4-40" name="__codelineno-4-40" href="#__codelineno-4-40"></a>
</span><span id="__span-4-41"><a id="__codelineno-4-41" name="__codelineno-4-41" href="#__codelineno-4-41"></a>  <span class="n">sampling_params</span> <span class="o">=</span> <span class="n">SamplingParams</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
</span><span id="__span-4-42"><a id="__codelineno-4-42" name="__codelineno-4-42" href="#__codelineno-4-42"></a>
</span><span id="__span-4-43"><a id="__codelineno-4-43" name="__codelineno-4-43" href="#__codelineno-4-43"></a>  <span class="n">ktc</span><span class="o">=</span><span class="n">KVTransferConfig</span><span class="p">(</span>
</span><span id="__span-4-44"><a id="__codelineno-4-44" name="__codelineno-4-44" href="#__codelineno-4-44"></a>      <span class="n">kv_connector</span><span class="o">=</span><span class="s2">&quot;SharedStorageConnector&quot;</span><span class="p">,</span>
</span><span id="__span-4-45"><a id="__codelineno-4-45" name="__codelineno-4-45" href="#__codelineno-4-45"></a>      <span class="n">kv_role</span><span class="o">=</span><span class="s2">&quot;kv_both&quot;</span><span class="p">,</span>
</span><span id="__span-4-46"><a id="__codelineno-4-46" name="__codelineno-4-46" href="#__codelineno-4-46"></a>      <span class="n">kv_connector_extra_config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;shared_storage_path&quot;</span><span class="p">:</span> <span class="s2">&quot;local_storage&quot;</span><span class="p">},</span>
</span><span id="__span-4-47"><a id="__codelineno-4-47" name="__codelineno-4-47" href="#__codelineno-4-47"></a>  <span class="p">)</span>
</span><span id="__span-4-48"><a id="__codelineno-4-48" name="__codelineno-4-48" href="#__codelineno-4-48"></a>
</span><span id="__span-4-49"><a id="__codelineno-4-49" name="__codelineno-4-49" href="#__codelineno-4-49"></a>  <span class="n">llm</span> <span class="o">=</span> <span class="n">LLM</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;TinyLlama/TinyLlama-1.1B-Chat-v1.0&quot;</span><span class="p">,</span> <span class="n">kv_transfer_config</span><span class="o">=</span><span class="n">ktc</span><span class="p">)</span>
</span><span id="__span-4-50"><a id="__codelineno-4-50" name="__codelineno-4-50" href="#__codelineno-4-50"></a>
</span><span id="__span-4-51"><a id="__codelineno-4-51" name="__codelineno-4-51" href="#__codelineno-4-51"></a>  <span class="n">prefill_done</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>  <span class="c1"># block waiting for KV cache from prefill instance</span>
</span><span id="__span-4-52"><a id="__codelineno-4-52" name="__codelineno-4-52" href="#__codelineno-4-52"></a>
</span><span id="__span-4-53"><a id="__codelineno-4-53" name="__codelineno-4-53" href="#__codelineno-4-53"></a>  <span class="c1"># Internally it&#39;ll first fetch KV cache before starting the decoding loop</span>
</span><span id="__span-4-54"><a id="__codelineno-4-54" name="__codelineno-4-54" href="#__codelineno-4-54"></a>  <span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>
</span><span id="__span-4-55"><a id="__codelineno-4-55" name="__codelineno-4-55" href="#__codelineno-4-55"></a>
</span><span id="__span-4-56"><a id="__codelineno-4-56" name="__codelineno-4-56" href="#__codelineno-4-56"></a><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
</span><span id="__span-4-57"><a id="__codelineno-4-57" name="__codelineno-4-57" href="#__codelineno-4-57"></a>  <span class="n">prefill_done</span> <span class="o">=</span> <span class="n">Event</span><span class="p">()</span>
</span><span id="__span-4-58"><a id="__codelineno-4-58" name="__codelineno-4-58" href="#__codelineno-4-58"></a>  <span class="n">prefill_process</span> <span class="o">=</span> <span class="n">Process</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">run_prefill</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">prefill_done</span><span class="p">,))</span>
</span><span id="__span-4-59"><a id="__codelineno-4-59" name="__codelineno-4-59" href="#__codelineno-4-59"></a>  <span class="n">decode_process</span> <span class="o">=</span> <span class="n">Process</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">run_decode</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">prefill_done</span><span class="p">,))</span>
</span><span id="__span-4-60"><a id="__codelineno-4-60" name="__codelineno-4-60" href="#__codelineno-4-60"></a>
</span><span id="__span-4-61"><a id="__codelineno-4-61" name="__codelineno-4-61" href="#__codelineno-4-61"></a>  <span class="n">prefill_process</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</span><span id="__span-4-62"><a id="__codelineno-4-62" name="__codelineno-4-62" href="#__codelineno-4-62"></a>  <span class="n">decode_process</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</span><span id="__span-4-63"><a id="__codelineno-4-63" name="__codelineno-4-63" href="#__codelineno-4-63"></a>
</span><span id="__span-4-64"><a id="__codelineno-4-64" name="__codelineno-4-64" href="#__codelineno-4-64"></a>  <span class="n">decode_process</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
</span><span id="__span-4-65"><a id="__codelineno-4-65" name="__codelineno-4-65" href="#__codelineno-4-65"></a>  <span class="n">prefill_process</span><span class="o">.</span><span class="n">terminate</span><span class="p">()</span>
</span></code></pre></div>
<blockquote>
<p>[!NOTE]
我也尝试过 <code>LMCache</code> [11]，它是最快的生产级的连接器（使用 NVIDIA 的 NIXL 作为后端），但它仍处于前沿，我遇到了一些错误。由于其大部分复杂性存在于外部仓库中，因此 <code>SharedStorageConnector</code> 是一个更好的解释选择。</p>
</blockquote>
<p>以下是 vLLM 中的步骤：</p>
<ol>
<li>
<p><strong>实例化</strong> — 在引擎构建期间，在两个地方创建连接器：
    - 在 worker 的 init device 过程中（在 init worker 分布式环境函数下），角色为“worker”。
    - 在调度器构造函数中，角色为“scheduler”。</p>
</li>
<li>
<p><strong>缓存查找</strong> — 当调度器处理来自 <code>waiting</code> 队列的 prefill 请求时（在本地 prefix-cache 检查之后），它会调用连接器的 <code>get_num_new_matched_tokens</code>。这会在 KV-cache 服务器中检查外部缓存的 token。Prefill 在这里总是看到 0；decode 可能会有缓存命中。在调用 <code>allocate_slots</code> 之前，将结果添加到本地计数中。</p>
</li>
<li>
<p><strong>状态更新</strong> — 调度器然后调用 <code>connector.update_state_after_alloc</code>，它记录了有缓存的请求（对 prefill 是无操作）。</p>
</li>
<li>
<p><strong>构建元数据对象</strong> — 在调度结束时，调度器调用 <code>meta = connector.build_connector_meta</code>：
    - Prefill 添加所有 <code>is_store=True</code> 的请求（以上传 KV）。
    - Decode 添加 <code>is_store=False</code> 的请求（以获取 KV）。</p>
</li>
<li>
<p><strong>上下文管理器</strong> — 在前向传播之前，引擎进入一个 KV-connector 上下文管理器：
    - 进入时：调用 <code>kv_connector.start_load_kv</code>。对于 decode，这将从外部服务器加载 KV 并将其注入到 paged memory 中。对于 prefill，这是一个无操作。
    - 退出时：调用 <code>kv_connector.wait_for_save</code>。对于 prefill，这将阻塞直到 KV 上传到外部服务器。对于 decode，这是一个无操作。</p>
</li>
</ol>
<p>这是一个图示示例：</p>
<p><img alt="图 12：disaggregated P/D" src="Inside%20vLLM%20Anatomy%20of%20a%20High-Throughput%20LLM%20Inference%20System.assets/pd.png" /></p>
<blockquote>
<p>[!NOTE] <strong>附加说明：</strong></p>
<ul>
<li>对于 <code>SharedStorageConnector</code>，“外部服务器”只是一个本地文件系统。</li>
<li>根据配置，KV 传输也可以逐层进行（在每个注意力层之前/之后）。</li>
<li>Decode 只在其请求的第一步加载一次外部 KV；之后它在本地计算/存储。
</li>
</ul>
</blockquote>
<h3 id="uniprocexecutor-multiprocexecutor">从 UniprocExecutor 到 MultiProcExecutor<a class="headerlink" href="#uniprocexecutor-multiprocexecutor" title="Permanent link">&para;</a></h3>
<p>掌握了核心技术后，我们现在可以讨论扩展了。</p>
<p>假设您的模型权重不再适合单个 GPU 的 VRAM。</p>
<p>第一个选项是使用 tensor parallelism（例如，<code>TP=8</code>）将模型分片到同一节点上的多个 GPU。如果模型仍然不适合，下一步是跨节点的 pipeline parallelism。</p>
<blockquote>
<p>[!NOTE] <strong>注意：</strong></p>
<ul>
<li>节点内带宽明显高于节点间带宽，这就是为什么 tensor parallelism (TP) 通常优于 pipeline parallelism (PP)。（PP 传输的数据比 TP 少也是事实。）</li>
<li>我没有涵盖 expert parallelism (EP)，因为我们专注于标准的 Transformer 而不是 MoE，也没有涵盖 sequence parallelism，因为 TP 和 PP 在实践中是最常用的。</li>
</ul>
</blockquote>
<p>在这个阶段，我们需要多个 GPU 进程（worker）和一个协调它们的编排层。这正是 <code>MultiProcExecutor</code> 所提供的。</p>
<p><img alt="图 13：TP=8 设置中的 MultiProcExecutor（驱动 worker 为 rank 0）" src="Inside%20vLLM%20Anatomy%20of%20a%20High-Throughput%20LLM%20Inference%20System.assets/multiprocexecutor.png" /></p>
<p>这在 vLLM 中是如何工作的：</p>
<ol>
<li><code>MultiProcExecutor</code> 初始化一个 <code>rpc_broadcast_mq</code> 消息队列（在底层使用共享内存实现）。</li>
<li>构造函数遍历 <code>world_size</code>（例如 <code>TP=8 ⇒ world_size=8</code>）并通过 <code>WorkerProc.make_worker_process</code> 为每个 rank 派生一个守护进程。</li>
</ol>
<ul>
<li><strong>rank</strong>: 分布式进程组中, 每个进程的唯一编号</li>
</ul>
<ol>
<li>对于每个 worker，父进程首先创建一个读写管道。</li>
<li>新进程运行 <code>WorkerProc.worker_main</code>，它实例化一个 worker（经历与 <code>UniprocExecutor</code> 中相同的“初始化设备”、“加载模型”等过程）。</li>
<li>每个 worker 确定它是否是驱动程序（TP 组中的 rank 0）或普通 worker。每个 worker 设置两个队列：
    - <code>rpc_broadcast_mq</code>（与父进程共享）用于接收工作。
    - <code>worker_response_mq</code> 用于发回响应。</li>
<li>在初始化期间，每个子进程通过管道将其 <code>worker_response_mq</code> 句柄发送给父进程。一旦全部收到，父进程就会解除阻塞——这完成了协调。</li>
<li>Worker 然后进入一个忙碌循环，在 <code>rpc_broadcast_mq.dequeue</code> 上阻塞。当一个work item到达时，它们执行它（就像在 <code>UniprocExecutor</code> 中一样，但现在使用 TP/PP 特定的分区工作）。结果通过 <code>worker_response_mq.enqueue</code> 发回。</li>
</ol>
<ul>
<li>每个<code>rpc_broadcast_mq</code>的work item都被</li>
</ul>
<ol>
<li>在运行时，当一个请求到达时，<code>MultiProcExecutor</code> 将其排入所有子 worker 的 <code>rpc_broadcast_mq</code>（非阻塞）。然后它在指定的输出 rank 的 <code>worker_response_mq.dequeue</code> 上等待以收集最终结果。</li>
</ol>
<p>从引擎的角度来看，没有任何改变——所有这些多进程复杂性都通过调用 Model Executor 的 <code>execute_model</code> 抽象掉了。</p>
<ul>
<li>在 <code>UniProcExecutor</code> 的情况下：execute_model 直接导致在 worker 上调用 execute_model</li>
<li>在 <code>MultiProcExecutor</code> 的情况下：execute_model 间接导致通过 <code>rpc_broadcast_mq</code> 在每个 worker 上调用 execute_model</li>
</ul>
<p>此时，我们可以使用相同的引擎接口运行资源允许的任何大小的模型。</p>
<p>下一步是横向扩展：启用 data parallelism (<code>DP &gt; 1</code>)，跨节点复制模型，添加一个轻量级的 DP 协调层，在副本之间引入负载均衡，并在前面放置一个或多个 API 服务器来处理传入流量。</p>
<h3 id="vllm">分布式系统服务 vLLM<a class="headerlink" href="#vllm" title="Permanent link">&para;</a></h3>
<blockquote>
<p>[!IMPORTANT] 记录:
这一段在没有上手代码的情况下有点难理解, 未来考虑重新阅读</p>
</blockquote>
<p>设置服务基础设施有很多方法，但为了保持具体，这里有一个例子：假设我们有两个 H100 节点，并希望在它们上面运行四个 vLLM 引擎。</p>
<p>如果模型需要 <code>TP=4</code>，我们可以这样配置节点。</p>
<p><img alt="图 14：具有 2 个 8xH100 节点的服务器配置（1 个无头，1 个 api 服务器）" src="Inside%20vLLM%20Anatomy%20of%20a%20High-Throughput%20LLM%20Inference%20System.assets/server_setup.png" /></p>
<p>在第一个节点上，以无头模式运行引擎（无 API 服务器），并使用以下参数：</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>vllm<span class="w"> </span>serve<span class="w"> </span>&lt;model-name&gt;<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="w">  </span>--tensor-parallel-size<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="w">  </span>--data-parallel-size<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a><span class="w">  </span>--data-parallel-size-local<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a><span class="w">  </span>--data-parallel-start-rank<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a><span class="w">  </span>--data-parallel-address<span class="w"> </span>&lt;master-ip&gt;<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a><span class="w">  </span>--data-parallel-rpc-port<span class="w"> </span><span class="m">13345</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a><span class="w">  </span>--headless
</span></code></pre></div>
<p>并在另一个节点上运行相同的命令，但稍作调整：</p>
<ul>
<li>无 <code>--headless</code></li>
<li>修改 DP 起始 rank</li>
</ul>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>vllm<span class="w"> </span>serve<span class="w"> </span>&lt;model-name&gt;<span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a><span class="w">  </span>--tensor-parallel-size<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span class="w">  </span>--data-parallel-size<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a><span class="w">  </span>--data-parallel-size-local<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a><span class="w">  </span>--data-parallel-start-rank<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a><span class="w">  </span>--data-parallel-address<span class="w"> </span>&lt;master-ip&gt;<span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a><span class="w">  </span>--data-parallel-rpc-port<span class="w"> </span><span class="m">13345</span>
</span></code></pre></div>
<blockquote>
<p>[!NOTE]
这假设网络已配置，以便所有节点都可以访问指定的 IP 和端口。</p>
</blockquote>
<p>这在 VLLM 中是如何工作的？</p>
<h4 id="_4">在无头服务器节点上<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h4>
<p>在无头节点上，一个 <code>CoreEngineProcManager</code> 启动 2 个进程（根据 <code>--data-parallel-size-local</code>），每个进程运行 <code>EngineCoreProc.run_engine_core</code>。这些函数中的每一个都创建一个 <code>DPEngineCoreProc</code>（引擎核心），然后进入其忙碌循环。</p>
<p><code>DPEngineCoreProc</code> 初始化其父 <code>EngineCoreProc</code>（<code>EngineCore</code> 的子类），它：</p>
<ol>
<li>创建一个 <code>input_queue</code> 和 <code>output_queue</code> (<code>queue.Queue</code>)。</li>
<li>使用 <code>DEALER</code> ZMQ 套接字（异步消息库）与另一节点上的前端进行初始握手，并接收协调地址信息。</li>
<li>初始化 DP 组（例如使用 NCCL 后端）。</li>
<li>使用 <code>MultiProcExecutor</code> (<code>TP=4</code> on 4 GPUs，如前所述）初始化 <code>EngineCore</code>。</li>
<li>创建一个 <code>ready_event</code> (<code>threading.Event</code>)。</li>
<li>启动一个运行 <code>process_input_sockets(…, ready_event)</code> 的输入守护线程 (<code>threading.Thread</code>)。类似地启动一个输出线程。</li>
<li>仍在主线程中，等待 <code>ready_event</code>，直到跨越 2 个节点的所有 4 个进程中的所有输入线程都完成了协调握手，最终执行 <code>ready_event.set()</code>。</li>
<li>一旦解除阻塞，就向前端发送一个“就绪”消息，其中包含元数据（例如，paged KV cache 内存中可用的 <code>num_gpu_blocks</code>）。</li>
<li>然后，主、输入和输出线程进入各自的忙碌循环。</li>
</ol>
<p>TL;DR: 我们最终得到 4 个子进程（每个 DP 副本一个），每个进程运行一个主、输入和输出线程。它们与 DP 协调器和前端完成协调握手，然后每个进程的三个线程都在稳态忙碌循环中运行。</p>
<p><img alt="图 15：具有 4 个 DP 副本运行 4 个 DPEngineCoreProc 的分布式系统" src="Inside%20vLLM%20Anatomy%20of%20a%20High-Throughput%20LLM%20Inference%20System.assets/dpenginecoreproc.png" /></p>
<p><strong>当前稳态</strong>：</p>
<ul>
<li><strong>输入线程</strong> — 在输入套接字上阻塞，直到从 API 服务器路由一个请求；收到后，它解码有效负载，通过 <code>input_queue.put_nowait(...)</code> 将一个工作项排队，然后返回到在套接字上阻塞。</li>
<li><strong>主线程</strong> — 在 <code>input_queue.get(...)</code> 上唤醒，将请求馈送到引擎；<code>MultiProcExecutor</code> 运行前向传播并将结果排队到 <code>output_queue</code>。</li>
<li><strong>输出线程</strong> — 在 <code>output_queue.get(...)</code> 上唤醒，将结果发回 API 服务器，然后恢复阻塞。</li>
</ul>
<p><strong>附加机制</strong>：</p>
<ul>
<li><strong>DP wave counter</strong> — 系统跟踪“wave”；当所有引擎都变为空闲时，它们会静止下来，当新工作到达时，计数器会增加（对协调/指标有用）。</li>
<li><strong>控制消息</strong> — API 服务器可以发送的不仅仅是推理请求（例如，中止和实用程序/控制 RPC）。</li>
<li><strong>用于lockstep的虚拟步骤</strong> — 如果任何 DP 副本有工作，所有副本都执行一个前向步骤；没有请求的副本执行一个虚拟步骤以参与所需的同步点（避免阻塞活动副本）。</li>
</ul>
<blockquote>
<p>[!NOTE]
Lockstep说明：这实际上只对 MoE 模型是必需的，其中 expert 层形成一个 EP 或 TP 组，而 attention 层仍然是 DP。目前总是与 DP 一起完成——这只是因为“内置”非 MoE DP 的用途有限，因为您可以只运行多个独立的 vLLM，并以正常方式在它们之间进行负载均衡。</p>
</blockquote>
<p>现在是第二部分，API 服务器节点上发生了什么？</p>
<h4 id="api">在 API 服务器节点上<a class="headerlink" href="#api" title="Permanent link">&para;</a></h4>
<p>我们实例化一个 <code>AsyncLLM</code> 对象（LLM 引擎的 asyncio 包装器）。在内部，这会创建一个 <code>DPLBAsyncMPClient</code>（data-parallel、load-balancing、asynchronous、multiprocessing client）。</p>
<p>在 <code>MPClient</code> 的父类中，<code>launch_core_engines</code> 函数运行并：</p>
<ol>
<li>创建用于启动握手的 ZMQ 地址（如在无头节点上所见）。</li>
<li>派生一个 <code>DPCoordinator</code> 进程。</li>
<li>创建一个 <code>CoreEngineProcManager</code>（与无头节点上相同）。</li>
</ol>
<p>在 <code>AsyncMPClient</code> (<code>MPClient</code> 的子类) 中，我们：</p>
<ol>
<li>创建一个 <code>outputs_queue</code> (<code>asyncio.Queue</code>)。</li>
<li>我们创建一个 asyncio 任务 <code>process_outputs_socket</code>，它（通过输出套接字）与所有 4 个 <code>DPEngineCoreProc</code> 的输出线程通信，并写入 <code>outputs_queue</code>。</li>
<li>随后，<code>AsyncLLM</code> 的另一个 asyncio 任务 <code>output_handler</code> 从此队列中读取，并最终将信息发送到 <code>create_completion</code> 函数。</li>
</ol>
<p>在 <code>DPAsyncMPClient</code> 中，我们创建一个 asyncio 任务 <code>run_engine_stats_update_task</code>，它与 DP 协调器通信。</p>
<p>DP 协调器在前端（API 服务器）和后端（引擎核心）之间进行协调。它：</p>
<ul>
<li>定期向前端的 <code>run_engine_stats_update_task</code> 发送负载均衡信息（队列大小、等待/运行中的请求）。</li>
<li>通过动态更改引擎数量来处理来自前端的 <code>SCALE_ELASTIC_EP</code> 命令（仅适用于 Ray 后端）。</li>
<li>向后端发送 <code>START_DP_WAVE</code> 事件（由前端触发）并报告 wave-state 更新。</li>
</ul>
<p>总而言之，前端 (<code>AsyncLLM</code>) 运行多个 asyncio 任务（请记住：并发，非并行）：</p>
<ul>
<li>一类任务通过 <code>generate</code> 路径处理输入请求（每个新的客户端请求都会派生一个新的 asyncio 任务）。</li>
<li>两个任务（<code>process_outputs_socket</code>、<code>output_handler</code>）处理来自底层引擎的输出消息。</li>
<li>一个任务（<code>run_engine_stats_update_task</code>）维护与 DP 协调器的通信：发送 wave 触发器、轮询 LB 状态以及处理动态扩展请求。</li>
</ul>
<p>最后，主服务器进程创建一个 FastAPI 应用程序并挂载诸如 <code>OpenAIServingCompletion</code> 和 <code>OpenAIServingChat</code> 之类的端点，这些端点公开 <code>/completion</code>、<code>/chat/completion</code> 等。然后通过 Uvicorn 提供堆栈服务。</p>
<p>那么，把所有东西放在一起，这就是完整的请求生命周期！</p>
<p>您从终端发送：</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>http://localhost:8000/v1/completions<span class="w"> </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="s1">  &quot;model&quot;: &quot;TinyLlama/TinyLlama-1.1B-Chat-v1.0&quot;,</span>
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a><span class="s1">  &quot;prompt&quot;: &quot;The capital of France is&quot;,</span>
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="s1">  &quot;max_tokens&quot;: 50,</span>
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a><span class="s1">  &quot;temperature&quot;: 0.7</span>
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a><span class="s1">}&#39;</span>
</span></code></pre></div>
<p>接下来会发生什么：</p>
<ol>
<li>请求到达 API 服务器上 <code>OpenAIServingCompletion</code> 的 <code>create_completion</code> 路由。</li>
<li>该函数异步地对prompt进行分词，并准备元数据（请求 ID、采样参数、时间戳等）。</li>
<li>然后它调用 <code>AsyncLLM.generate</code>，其流程与同步引擎相同，最终调用 <code>DPAsyncMPClient.add_request_async</code>。</li>
<li>这反过来又调用 <code>get_core_engine_for_request</code>，它根据 DP 协调器的状态在引擎之间进行负载均衡（选择得分最低/负载最低的那个：<code>score = len(waiting) * 4 + len(running)</code>）。</li>
<li><code>ADD</code> 请求被发送到所选引擎的 <code>input_socket</code>。</li>
<li>在该引擎处：
    - 输入线程 — 解除阻塞，从输入套接字解码数据，并将一个工作项放入主线程的 <code>input_queue</code> 中。
    - 主线程 — 在 <code>input_queue</code> 上解除阻塞，将请求添加到引擎，并重复调用 <code>engine_core.step()</code>，将中间结果排队到 <code>output_queue</code>，直到满足停止条件。
    - 输出线程 — 在 <code>output_queue</code> 上解除阻塞，并通过输出套接字发回结果。</li>
</ol>
<blockquote>
<p>[!NOTE]
提醒：<code>step()</code> 调用调度器、Model Executor（它本身可以是 <code>MultiProcExecutor</code>！）等。我们已经看到过这个了！</p>
</blockquote>
<ol>
<li>这些结果触发了 <code>AsyncLLM</code> 输出 asyncio 任务（<code>process_outputs_socket</code> 和 <code>output_handler</code>），这些任务将 token 传播回 FastAPI 的 <code>create_completion</code> 路由。</li>
<li>FastAPI 附加元数据（完成原因、logprobs、使用信息等）并通过 Uvicorn 向您的终端返回一个 <code>JSONResponse</code>！</li>
</ol>
<p>就这样，您的补全回来了——整个分布式机制隐藏在一个简单的 <code>curl</code> 命令后面！:) 太有趣了！！！</p>
<blockquote>
<p><strong>附加说明：</strong></p>
<ul>
<li>当添加更多 API 服务器时，负载均衡在 OS/套接字级别处理。从应用程序的角度来看，没有重大变化——复杂性是隐藏的。</li>
<li>使用 Ray 作为 DP 后端，您可以公开一个 URL 端点（<code>/scale_elastic_ep</code>），该端点可以自动扩展引擎副本的数量。</li>
</ul>
</blockquote>
<h3 id="-vs">基准测试和自动调优-延迟vs吞吐量<a class="headerlink" href="#-vs" title="Permanent link">&para;</a></h3>
<p>到目前为止，我们一直在分析“气体颗粒”——请求如何在引擎/系统中流动的内部原理。现在是时候放大并从整体上看待系统，并问：我们如何衡量一个推理系统的性能？</p>
<p>在最高层次上，有两个相互竞争的指标：</p>
<ol>
<li><strong>延迟</strong> — 从提交请求到返回 token 的时间</li>
<li><strong>吞吐量</strong> — 系统每秒可以生成/处理的 token/请求数</li>
</ol>
<p><strong>延迟</strong>对于交互式应用程序最重要，用户在这些应用程序中等待响应。</p>
<p><strong>吞吐量</strong>在离线工作负载中很重要，例如用于预/后训练运行的合成数据生成、数据清理/处理，以及通常——任何类型的离线批处理推理作业。</p>
<p>在解释为什么延迟和吞吐量相互竞争之前，让我们定义一些常见的推理指标：</p>
<table>
<thead>
<tr>
<th>指标</th>
<th>定义</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>TTFT</code> (首个 token 时间)</td>
<td>从提交请求到收到第一个输出 token 的时间</td>
</tr>
<tr>
<td><code>ITL</code> (token 间延迟)</td>
<td>两个连续 token 之间的时间（例如，从 token i-1 到 token i）</td>
</tr>
<tr>
<td><code>TPOT</code> (每个输出 token 的时间)</td>
<td>请求中所有输出 token 的<strong>平均 ITL</strong></td>
</tr>
<tr>
<td><code>Latency / E2E</code> (端到端延迟)</td>
<td>处理请求的总时间，即 TTFT + 所有 ITL 的总和，或者等效地，提交请求和接收最后一个输出 token 之间的时间</td>
</tr>
<tr>
<td><code>Throughput</code></td>
<td>每秒处理的总 token 数（输入、输出或两者），或者每秒请求数</td>
</tr>
<tr>
<td><code>Goodput</code></td>
<td>满足服务级别目标 (SLO) 的吞吐量，例如最大 TTFT、TPOT 或 e2e 延迟。例如，只计算满足这些 SLO 的请求中的 token</td>
</tr>
</tbody>
</table>
<p><img alt="图 16：ttft, itl, e2e 延迟" src="Inside%20vLLM%20Anatomy%20of%20a%20High-Throughput%20LLM%20Inference%20System.assets/latency_diagram.png" /></p>
<p>这是一个解释这两个指标竞争性质的简化模型。</p>
<blockquote>
<p><strong>假设：</strong> 权重 I/O 而不是 KV cache I/O 占主导地位；即我们处理的是短序列。</p>
</blockquote>
<p>当观察批处理大小 <code>B</code> 如何影响单个 decode 步骤时，这种权衡变得清晰。当 <code>B ↓</code> 趋向于 1 时，ITL 下降：每一步的工作量减少，token 不会与其他 token “竞争”。当 <code>B ↑</code> 趋向于无穷大时，ITL 上升，因为我们每一步做更多的 FLOPs——但吞吐量提高了（直到我们达到峰值性能），因为权重 I/O 在更多的 token 上被摊销了。</p>
<p>一个 roofline 模型有助于理解这一点：在饱和批次 <code>B_sat</code> 以下，步骤时间由 HBM 带宽主导（逐层将权重流式传输到片上内存），因此步骤延迟几乎是平坦的——计算 1 个 vs 10 个 token 可能需要相似的时间。超过 <code>B_sat</code>，kernel 变得受计算限制，步骤时间大致随 <code>B</code> 增长；每个额外的 token 都会增加 ITL。</p>
<p><img alt="图 17：roofline 性能模型" src="Inside%20vLLM%20Anatomy%20of%20a%20High-Throughput%20LLM%20Inference%20System.assets/roofline.png" /></p>
<blockquote>
<p><strong>注意：</strong> 为了更严谨地处理，我们必须考虑 kernel 自动调优：随着 <code>B</code> 的增长，运行时可能会切换到对该形状更有效的 kernel，从而改变实现的性能 <code>P_kernel</code>。步骤延迟为 <code>t = FLOPs_step / P_kernel</code>，其中 <code>FLOPs_step</code> 是该步骤中的工作量。您可以看到，当 <code>P_kernel</code> 达到 <code>P_peak</code> 时，每一步更多的计算将直接导致延迟增加。</p>
</blockquote>
<h4 id="vllm_1">如何在 vLLM 中进行基准测试<a class="headerlink" href="#vllm_1" title="Permanent link">&para;</a></h4>
<p>vLLM 提供了一个 <code>vllm bench {serve,latency,throughput}</code> CLI，它包装了 vllm / benchmarks / {server,latency,throughput}.py。</p>
<p>以下是这些脚本的作用：</p>
<ul>
<li><strong>latency</strong> — 使用短输入（默认为 32 个 token）并以小批量（默认为 8）采样 128 个输出 token。它运行几次迭代并报告该批次的 e2e 延迟。</li>
<li><strong>throughput</strong> — 一次性提交一组固定的prompt（默认：1000 个 ShareGPT 样本）（也称为 <code>QPS=Inf</code> 模式），并报告整个运行过程中的输入/输出/总 token 数和每秒请求数。</li>
<li><strong>serve</strong> — 启动一个 vLLM 服务器，并通过从泊松（或更一般的，伽马）分布中采样请求的到达间隔时间来模拟真实世界的工作负载。它在一个时间窗口内发送请求，测量我们讨论过的所有指标，并且可以选择性地强制执行服务器端最大并发数（通过一个信号量，例如将服务器限制为 64 个并发请求）。</li>
</ul>
<p>以下是如何运行延迟脚本的示例：</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>vllm<span class="w"> </span>bench<span class="w"> </span>latency<span class="w"> </span><span class="se">\</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a><span class="w">  </span>--model<span class="w"> </span>&lt;model-name&gt;<span class="w"> </span><span class="se">\</span>
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a><span class="w">  </span>--input-tokens<span class="w"> </span><span class="m">32</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a><span class="w">  </span>--output-tokens<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a><span class="w">  </span>--batch-size<span class="w"> </span><span class="m">8</span>
</span></code></pre></div>
<blockquote>
<p>[!NOTE]
CI 中使用的基准测试配置位于 <code>.buildkite/nightly-benchmarks/tests</code> 下。</p>
</blockquote>
<p>还有一个自动调优脚本，它驱动 serve 基准测试来找到满足目标 SLO（例如，“在保持 p99 e2e &lt; 500 ms 的同时最大化吞吐量”）的参数设置，并返回一个建议的配置。</p>
<h3 id="_5">结语<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h3>
<p>我们从基本的引擎核心 (<code>UniprocExecutor</code>) 开始，添加了像 speculative decoding 和 prefix caching 这样的高级功能，扩展到 <code>MultiProcExecutor</code> (具有 <code>TP/PP &gt; 1</code>)，最后横向扩展，将所有东西包装在异步引擎和分布式服务堆栈中——最后讨论了如何衡量系统性能。</p>
<p>vLLM 还包括我跳过的专门处理。例如：</p>
<ul>
<li><strong>多样化的硬件后端</strong>：TPU、AWS Neuron (Trainium/Inferentia) 等。</li>
<li><strong>架构/技术</strong>：<code>MLA</code>、<code>MoE</code>、encoder-decoder (例如 Whisper)、pooling/embedding 模型、<code>EPLB</code>、<code>m-RoPE</code>、<code>LoRA</code>、<code>ALiBi</code>、无注意力变体、滑动窗口注意力、多模态 LM 和状态空间模型 (例如 Mamba/Mamba-2, Jamba)</li>
<li><strong>TP/PP/SP</strong></li>
<li><strong>混合 KV-cache 逻辑</strong> (Jenga)，更复杂的采样方法如 beam sampling 等</li>
<li><strong>实验性</strong>：异步调度</li>
</ul>
<p>好处是，这些中的大多数都与上面描述的主流程正交——你几乎可以将它们视为“插件”（当然，在实践中存在一些耦合）。</p>
<p>我喜欢理解系统。话虽如此，在这个高度上，分辨率肯定会受到影响。在接下来的文章中，我将放大到特定的子系统并深入探讨细节。</p>
<blockquote>
<p><strong>联系我：</strong> 如果您在帖子中发现任何错误，请私信我 - 欢迎在 <a href="https://x.com/gordic_aleksa" title="null">X</a> 或 <a href="https://www.linkedin.com/in/aleksagordic/" title="null">LinkedIn</a> 上给我留言，或通过<a href="https://docs.google.com/forms/d/1z1fEirrN2xtGxAsJvptpM7yV4ByT5SF25S-XiMPrXNA" title="null">匿名反馈</a>留言。</p>
</blockquote>
<h4 id="_6">致谢<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h4>
<p>非常感谢 <a href="https://www.hyperstack.cloud/" title="null">Hyperstack</a> 在过去一年中为我的实验提供了 H100！</p>
<p>感谢 <a href="https://www.linkedin.com/in/nickhillprofile/" title="null">Nick Hill</a> (vLLM 核心贡献者, RedHat), <a href="https://github.com/youkaichao" title="null">Kaichao You</a> (vLLM 核心贡献者), <a href="https://x.com/marksaroufim" title="null">Mark Saroufim</a> (PyTorch), <a href="https://www.linkedin.com/in/kyle-kranen/" title="null">Kyle Krannen</a> (NVIDIA, Dynamo), 和 <a href="https://www.linkedin.com/in/ashish-vaswani-99892181/" title="null">Ashish Vaswani</a> 阅读了这篇博文的预发布版本并提供了反馈！</p>
<h4 id="_7">参考文献<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h4>
<ol>
<li>vLLM <a href="https://github.com/vllm-project/vllm" title="null">https://github.com/vllm-project/vllm</a></li>
<li>“Attention Is All You Need” <a href="https://arxiv.org/abs/1706.03762" title="null">https://arxiv.org/abs/1706.03762</a></li>
<li>“Efficient Memory Management for Large Language Model Serving with PagedAttention” <a href="https://arxiv.org/abs/2309.06180" title="null">https://arxiv.org/abs/2309.06180</a></li>
<li>“DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model” <a href="https://arxiv.org/abs/2405.04434" title="null">https://arxiv.org/abs/2405.04434</a></li>
<li>“Jenga: Effective Memory Management for Serving LLM with Heterogeneity” <a href="https://arxiv.org/abs/2503.18292" title="null">https://arxiv.org/abs/2503.18292</a></li>
<li>“Orca: A Distributed Serving System for Transformer-Based Generative Models” <a href="https://www.usenix.org/conference/osdi22/presentation/yu" title="null">https://www.usenix.org/conference/osdi22/presentation/yu</a></li>
<li>“XGrammar: Flexible and Efficient Structured Generation Engine for Large Language Models” <a href="https://arxiv.org/abs/2411.15100" title="null">https://arxiv.org/abs/2411.15100</a></li>
<li>“Accelerating Large Language Model Decoding with Speculative Sampling” <a href="https://arxiv.org/abs/2302.01318" title="null">https://arxiv.org/abs/2302.01318</a></li>
<li>“EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty” <a href="https://arxiv.org/abs/2401.15077" title="null">https://arxiv.org/abs/2401.15077</a></li>
<li>“Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads” <a href="https://arxiv.org/abs/2401.10774" title="null">https://arxiv.org/abs/2401.10774</a></li>
<li>LMCache <a href="https://github.com/LMCache/LMCache" title="null">https://github.com/LMCache/LMCache</a></li>
</ol>







  
  






                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="页脚" >
        
          
          <a href="../fzu_cs_course/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/FZU-SINTEF-Beamer-Template.html" class="md-footer__link md-footer__link--prev" aria-label="上一页: FZU-SINTEF-Beamer-Template">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                上一页
              </span>
              <div class="md-ellipsis">
                FZU-SINTEF-Beamer-Template
              </div>
            </div>
          </a>
        
        
          
          <a href="../csdiy/CMU%2010-414%20Deep%20Learning%20Systems/index.html" class="md-footer__link md-footer__link--next" aria-label="下一页: Index">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                下一页
              </span>
              <div class="md-ellipsis">
                Index
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["navigation.tabs", "navigation.indexes", "navigation.tabs.sticky", "navigation.tracking", "toc.follow", "content.action.edit", "navigation.footer", "navigation.path", "navigation.top", "search.suggest", "search.highlight", "search.share"], "search": "../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>